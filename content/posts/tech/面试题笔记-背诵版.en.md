---
title: "面试题笔记 背诵版"
date: 2023-03-16T22:54:20+08:00
categories: []
tags: []
description: ""
weight:
slug: ""
draft: false
disableShare: false
cover:
    image: ""
    caption: ""
    alt: ""
    relative: false
---

# 项目

## 一般问题

### 碰到的bug



### 最有技术含量的部分



## 动态代理

见：<https://juejin.cn/post/7011357346018361375>

### jdk动态代理

#### 原理

就是先实现代理接口的方法，生成一个匿名内部类，这个匿名内部类里的操作都是调用InvocationHandler的invoke方法，在invoke方法里完成代理

#### 使用步骤

1. 创建被代理类及接口（JDK代理是接口代理）
2. 创建Handle类实现 InvocationHandler接口 ，重写invoke方法
3. 通过Proxy的newProxyInstance()方法获取代理类对象
4. 通过代理类对象调用被代理类的方法

### cglib动态代理

#### 原理

就是修改需要代理的那个类的字节码，生成该类的子类并重写父类的方法，这个子类的方法都会调用回调函数intercept方法，从而完成代理

#### 使用步骤

1. new Enhancer()
2. 设置需要代理的类
3. 设置回调
4. 创建

#### jdk动态代理和cglib动态代理的区别

1. **原理不同：**JDK动态代理：利用反射机制生成一个实现代理接口的匿名类，在调用具体方法前调用InvokeHandler来处理。
   CGLib动态代理：利用ASM（开源的Java字节码编辑库，操作字节码）开源包，将代理对象类的class文件加载进来，通过修改其字节码生成子类来处理。所以jdk动态代理的方式创建代理对象效率较高，执行效率较低，CGLib创建效率较低，执行效率高。
2. **适用场景不同：**jdk动态代理目标类必须是接口类，cglib代理目标类不需要实现接口，但是不能是final类
3. **机制不同：**jdk动态代理是委托机制，因为代理类里无法直接调用被代理类的方法，所以委托InvocationHandler去调用目标类的方法，cglib动态代理是继承机制，代理类和被代理类是父子关系，所以代理类可以调用被代理类的方法，所以通过回调函数MethodInterceptor调用父类方法执行原始逻辑

### 静态代理

为需要代理的类抽象出一个接口，然后编写代理类实现这个接口，实现接口方法时就可以添加代理的逻辑

缺点：1、每个被代理类都要有一个代理类，代码比较冗余 2、一旦改动被代理类，代理类也得改动

#### 静态代理与动态代理的区别

- 静态代理在编译时就已经实现，编译完成后代理类是一个实际的class文件
- 动态代理是在运行时动态生成的，即编译完成后没有实际的class文件，而是在运行时动态生成的

## Netty

### 什么是Netty

Netty就是Java里NIO的封装，让用户可以很方便的使用Java的非阻塞IO

### Netty跟Java NIO有什么不同，为什么不直接使用JDK NIO类库？

说说NIO有什么缺点吧：

1. NIO的类库和API还是有点复杂，比如Buffer的使用 Selector编写复杂，如果对某个事件注册后，业务代码过于耦合，需要了解很多多线程的知识，熟悉网络编程，面对断连重连、保丢失、粘包等，处理复杂
2. NIO存在BUG，根据网上言论说是selector空轮训导致CPU飙升

Netty主要的优点有：

1. 统一的 API，支持多种传输类型，阻塞和非阻塞的。
2. 简单而强大的线程模型。
3. 自带编解码器解决 TCP 粘包/拆包问题，自带各种协议栈。
5. 比直接使用 Java 核心 API 有更高的吞吐量、更低的延迟、更低的资源消耗和更少的内存复制。
7. 社区活跃，成熟稳定，经历了大型项目的使用和考验，而且很多开源项目都使用到了 Netty， 比如我们经常接触的 Dubbo、RocketMQ 等等。

### Netty 应用场景了解么？

理论上来说，NIO 可以做的事情 ，使用 Netty 都可以做并且更好。Netty 主要用来做**网络通信**：

1. **作为 RPC 框架的网络通信工具** 
2. **实现一个自己的 HTTP 服务器** 
3. **实现一个即时通讯系统** 
4. **实现消息推送系统** 

基本只要是网络通信的都可以用Netty做

### Netty的核心组件

#### EventLoop

EventLoop 的主要作用实际就是负责监听网络事件并调用事件处理器进行相关 I/O 操作的处理。

#### Channel

**Channel** 接口是 **Netty** 对网络操作抽象类，它除了包括基本的 **I/O** 操作，如 **bind()**、**connect()**、**read()**、**write()** 等。

比较常用的**Channel**接口实现类是**NioServerSocketChannel**（服务端）和**NioSocketChannel**（客户端），这两个 **Channel** 可以和 **BIO** 编程模型中的**ServerSocket**以及**Socket**两个概念对应上。**Netty** 的 **Channel** 接口所提供的 **API**，大大地降低了直接使用 **Socket** 类的复杂性。

#### ChannelFuture

**Netty** 是异步非阻塞的，所有的 I/O 操作都为异步的。所以我们不能立刻得到操作的结果，我们可以通过 **ChannelFuture** 接口的 **addListener()** 方法注册一个 **ChannelFutureListener**，当操作执行完后，监听就会自动触发返回结果。

#### ChannelHandler 和 ChannelPipeline

ChannelHandler 用来处理 Channel 上的各种事件，分为入站、出站两种。所有 ChannelHandler 被连在一起了，连在一起形成的链就是 ChannelPipeline

### Bootstrap 和 ServerBootstrap 了解么？

1. Bootstrap是客户端，ServerBootstrap是服务端
2. Bootstrap调用connect连接，ServerBootstrap调用bind开启服务
3. Bootstrap 只需要配置一个EventLoopGroup ,而 ServerBootstrap需要配置两个线程组EventLoopGroup ，一个用于处理连接事件，一个用于处理读写事件。

### Netty的线程模型

Netty通过Reactor模型基于多路复用器接收并处理用户请求，内部实现了两个线程池，boss线程池和work线程池，其中boss线程池的线程负责处理请求的accept事件，当接收到accept事件的请求时，把对应的socket封装到一个NioSocketChannel中，并交给work线程池，其中work线程池负责请求的read和write事件，由对应的Handler处理。

单线程模型：所有I/O操作都由一个线程完成，即多路复用、事件分发和处理都是在一个Reactor线程上完成的。既要接收客户端的连接请求,向服务端发起连接，又要发送/读取请求或应答/响应消息。一个NIO 线程同时处理成百上千的链路，性能上无法支撑，速度慢，若线程进入死循环，整个程序不可用，对于高负载、大并发的应用场景不合适。

多线程模型：有一个NIO 线程（Acceptor） 只负责监听服务端，接收客户端的TCP 连接请求；NIO 线程池负责网络IO 的操作，即消息的读取、解码、编码和发送；1 个NIO 线程可以同时处理N 条链路，但是1 个链路只对应1 个NIO 线程，这是为了防止发生并发操作问题。但在并发百万客户端连接或需要安全认证时，一个Acceptor 线程可能会存在性能不足问题。

主从多线程模型：Acceptor 线程用于绑定监听端口，接收客户端连接，将SocketChannel 从主线程池的Reactor 线程的多路复用器上移除，重新注册到Sub 线程池的线程上，用于处理I/O 的读写等操作，从而保证mainReactor只负责接入认证、握手等操作

#### Reactor模型

建立新连接和处理读写操作分开就是Reactor模型

详见：<https://www.cnblogs.com/coding400/p/10865333.html>

### Netty的执行流程

#### 服务端

1. 创建ServerBootStrap实例
2. 设置并绑定Reactor线程池（线程模型）：EventLoopGroup，EventLoop就是处理所有注册到本线程的Selector上面的Channel
3. 设置并绑定服务端的channel（IO模型）
4. 创建处理网络事件的ChannelPipeline和handler
5. 绑定并启动监听端口
6. 当轮询到准备就绪的channel后，由Reactor线程：NioEventLoop执行pipline中的方法，最终调度并执行channelHandler

#### 客户端

1. 创建BootStrap实例
2. 设置并绑定Reactor线程池（线程模型）：EventLoopGroup，EventLoop就是处理所有注册到本线程的Selector上面的Channel
3. 设置并绑定服务端的channel（IO模型）
4. 创建处理网络事件的ChannelPipeline和handler
5. 发起连接

### TCP 粘包/拆包的原因及解决方法

#### 原因

**粘包：**

1. 应用程序写入数据小于套接字缓冲区大小，网卡将应用多次写入的数据发送到网络上，这将会发生粘包。
2. 接收方法不及时读取套接字缓冲区数据，这将发生粘包。

**拆包：**

1. 应用程序写入的数据大于套接字缓冲区大小，这将会发生拆包。
2. 进行MSS（最大报文长度）大小的TCP分段，当TCP报文长度-TCP头部长度>MSS的时候将发生拆包。

#### 解决办法

1. 发送端给每个数据包添加包首部，首部中应该至少包含数据包的长度，这样接收端在接收到数据后，通过读取包首部的长度字段，便知道每一个数据包的实际长度了。（FixedLengthFrameDecoder）
2. 发送端将每个数据包封装为固定长度（不够的可以通过补0填充），这样接收端每次从接收缓冲区中读取固定长度的数据就自然而然的把每个数据包拆分开来。（DelimiterBasedFrameDecoder）
3. 可以在数据包之间设置边界，如添加特殊符号，这样，接收端通过这个边界就可以将不同的数据包拆分开。（LengthFieldBasedFrameDecoder）
4. 通过自定义协议进行粘包和拆包的处理。（MessageToByteEncoder和ByteToMessageDecoder）

### Netty 长连接、心跳机制

#### 长连接

Netty的长连接其实就是TCP的长连接

TCP 在进行读写之前，server 与 client 之间必须提前建立一个连接。建立连接的过程，需要我们常说的三次握手，释放/关闭连接的话需要四次挥手。这个过程是比较消耗网络资源并且有时间延迟的。

所谓，短连接说的就是 server 端 与 client 端建立连接之后，读写完成之后就关闭掉连接，如果下一次再要互相发送消息，就要重新连接。短连接的优点很明显，就是管理和实现都比较简单，缺点也很明显，每一次的读写都要建立连接必然会带来大量网络资源的消耗，并且连接的建立也需要耗费时间。

长连接说的就是 client 向 server 双方建立连接之后，即使 client 与 server 完成一次读写，它们之间的连接并不会主动关闭，后续的读写操作会继续使用这个连接。长连接的可以省去较多的 TCP 建立和关闭的操作，降低对网络资源的依赖，节约时间。对于频繁请求资源的客户来说，非常适用长连接。

#### 心跳机制

在 TCP 保持长连接的过程中，可能会出现断网等网络异常出现，异常发生的时候， client 与 server 之间如果没有交互的话，他们是无法发现对方已经掉线的。为了解决这个问题, 我们就需要引入 **心跳机制** 。

心跳机制的工作原理是: 在 client 与 server 之间在一定时间内没有数据交互时, 即处于 idle 状态时, 客户端或服务器就会发送一个特殊的数据包给对方, 当接收方收到这个数据报文后, 也立即发送一个特殊的数据报文, 回应发送方, 此即一个 PING-PONG 交互。所以, 当某一端收到心跳消息后, 就知道了对方仍然在线, 这就确保 TCP 连接的有效性.

TCP 实际上自带的就有长连接选项，本身是也有心跳包机制，也就是 TCP 的选项：SO_KEEPALIVE。但是，TCP 协议层面的长连接灵活性不够。所以，一般情况下我们都是在应用层协议上实现自定义信跳机制的，也就是在 Netty 层面通过编码实现。通过 Netty 实现心跳机制的话，核心类是 IdleStateHandler 。

### Netty 的零拷贝

#### 操作系统的零拷贝

传统意义的拷贝是在发送数据的时候， 传统的实现方式是：

\1. File.read(bytes)

\2. Socket.send(bytes)

这种方式需要四次数据拷贝和四次上下文切换：

\1. 数据从磁盘读取到内核的read buffer

\2. 数据从内核缓冲区拷贝到用户缓冲区

\3. 数据从用户缓冲区拷贝到内核的socket buffer

\4. 数据从内核的socket buffer拷贝到网卡接口（硬件）的缓冲区

零拷贝的概念明显上面的第二步和第三步是没有必要的，通过java的FileChannel.transferTo方法，可以避免上面两次多余的拷贝（当然这需要底层操作系统支持）

\1. 调用transferTo,数据从文件由DMA引擎拷贝到内核read buffer

\2. 接着DMA从内核read buffer将数据拷贝到网卡接口buffer上面的两次操作都不需要CPU参与，所以就达到了零拷贝。

#### Netty 的零拷贝

Netty 的零拷贝主要包含三个方面：

1. Netty 的接收和发送 ByteBuffer 采用 DIRECT BUFFERS，使用堆外直接内存（注意直接内存可以内核态的缓冲区内存进行内存映射，也就是mmap）进行 Socket 读写，不需要进行字节缓冲区的二次拷贝。如果使用传统的堆内存（HEAP BUFFERS）进行 Socket 读写，JVM 会将堆内存 Buffer 拷贝一份到直接内存中，然后才写入 Socket 中。相比于堆外直接内存，消息在发送过程中多了一次缓冲区的内存拷贝。
2. Netty 提供了组合 Buffer 对象，可以聚合多个 ByteBuffer 对象，用户可以像操作一个 Buffer 那样方便的对组合 Buffer 进行操作，避免了传统通过内存拷贝的方式将几个小 Buffer 合并成一个大的 Buffer。
3. Netty 的文件传输采用了 transferTo 方法，它可以直接将文件缓冲区的数据发送到目标 Channel，避免了传统通过循环 write 方式导致的内存拷贝问题。

### NIO的空轮询bug

#### 原因

若Selector的轮询结果为空，也没有wakeup或新消息处理，则发生空轮询，CPU使用率100%

#### 解决方案

1. 对Selector的select操作周期进行统计，每完成一次空的select操作进行一次计数，
2. 若在某个周期内连续发生N次空轮询，则触发了epoll死循环bug。
3. 重建Selector，判断是否是其他线程发起的重建请求，若不是则将原SocketChannel从旧的Selector上去除注册，重新注册到新的Selector上，并将原来的Selector关闭。

### Netty 高性能表现在哪些方面

1. **IO 线程模型：**使用IO多路复用（同步非阻塞），用最少的资源做更多的事。
2. **零拷贝技术：**尽量减少不必要的内存拷贝，实现了更高效率的传输。
3. **内存池设计：**申请的内存可以重用，主要指直接内存。内部实现是用一颗二叉查找树管理内存分配情况。
4. **串形化处理读写：**避免使用锁带来的性能开销。即消息的处理尽可能在同一个线程内完成，期间不进行线程切换，这样就避免了多线程竞争和同步锁。表面上看，串行化设计似乎CPU利用率不高，并发程度不够。但是，通过调整NIO线程池的线程参数，可以同时启动多个串行化的线程并行运行，这种局部无锁化的串行线程设计相比一个队列-多个工作线程模型性能更优（这种串形化处理读写的设计相当于每个线程都有一个任务队列，使用时不用加锁，所以性能较高）。
5. **高性能序列化协议：**支持 protobuf 等高性能序列化协议。
6. **高效并发编程：**volatile的大量使用；CAS和原子类的广泛使用。

### Netty的内存池是怎么实现的

有点复杂

1. 首先会预申请一大块内存Arena，Arena由许多Chunk组成，而每个Chunk默认由2048个page组成。
2. Chunk通过AVL树的形式组织Page，每个叶子节点表示一个Page，而中间节点表示内存区域，节点自己记录它在整个Arena中的偏移地址。
3. 当区域被分配出去后，中间节点上的标记位会被标记，这样就表示这个中间节点以下的所有节点都已被分配了。

### 五种IO模型

阻塞IO、非阻塞IO、IO多路复用、信号驱动IO，异步IO

#### 同步与异步、阻塞与非阻塞

同步和异步描述的是消息通信的机制。

假如A调用B

同步：A发送request，B返回A需要的response

异步：A发送request，B马上返回空的response或者不返回，B操作完成后，调用A的callback或者给A发信号，将A需要的数据返回给B

阻塞和非阻塞描述的是程序在等待调用结果（消息，返回值）时的状态。

阻塞：阻塞调用是指调用方发出request的线程因为某种原因（如：等待系统资源）被服务方挂起，当服务方得到response后就唤醒挂起线程，并将response返回给调用方。

非阻塞：非阻塞调用是指调用方发出request的线程在没有等到结果时不会被挂起，直到得到response后才返回。

### BIO、NIO、AIO分别是什么？

BIO:同步并阻塞 ，服务器实现模式为一个连接一个线程，即客户端有连接请求时服务器端就需要启动一个线程进行处理，如果这个连接不做任何事情会造成不必要的线程开销，当然可以通过线程池机制改善。BIO方式适用于连接数目比较小且固定的架构，这种方式对服务器资源要求比较高

NIO:同步非阻塞 ，服务器实现模式为一个请求一个线程，即客户端发送的连接请求都会注册到多路复用器上，多路复用器轮询到连接有I/O请求时才启动一个线程进行处理。NIO方式适用于连接数目多且连接比较短（轻操作）的架构，比如聊天服务器

AIO:异步非阻塞 ，服务器实现模式为一个有效请求一个线程，客户端的I/O请求服务器处理之前就会返回，处理完成之后会调用回调函数来返回数据

### select、poll、epoll的机制及其区别？

1. 单个进程打开的文件描述符（fd文件句柄）不一致

select ：有最大连接数限制数为1024，单个进程所能打开的最大连接数由FD_ZETSIZE宏定义。

poll：poll本质上与select没有区别，但是它没有最大连接数的限制，原因是它是基于链表来存储的。

epoll：虽然连接有上限，但是很大，1G内存的机器可以打开10万左右的连接，以此类推。

2. 监听Socket的方式不一致

select ：轮询的方式，一个一个的socket检查过去，发现有socket活跃时才进行处理，当线性socket增多时，轮询的速度将会变得很慢，造成线性造成性能下降问题。

poll：对select稍微进行了优化，只是修改了文件描述符，但是监听socket的方式还是轮询。

epoll：epoll内核中实现是根据每个fd上的callback函数来实现的，只有活跃的socket才会主动调用callback，通知expoll来处理这个socket。（会将连接的socket注册到epoll中, 相当于socket的花名册, 如果有一个socket活跃了, 会回调一个函数, 通知epoll,赶紧过来处理）

select、poll、epoll时间复杂度分别是：O(n)、O(n)、O(1)

3. 内存空间拷贝方式（消息传递方式）不一致

select：内核想将消息传递到用户态，需要将数据从内核态拷贝到用户态,这个过程非常的耗时

poll：同上

epoll：epoll的内核和用户空间共享一块内存，因此内存态数据和用户态数据是共享的

### Netty底层用的什么？

Java层面用的NIO的Selector机制，操作系统层面Linux用的epoll，Windows用的IOCP

## 序列化

### 序列化和反序列化有什么作用

1. **实现了数据的持久化**：永久性保存对象，保存对象的字节序列到本地文件或者数据库中
2. **序列化实现远程通**：通过序列化以字节流的形式使对象在网络中进行传递和接收
3. 通过序列化在进程间传递对象

### Serializable接口的作用

其实Serializable接口只是一个标识，序列化由ObjectInputStream和ObjectOutputStream执行，具体操作在jvm里

#### Serializable和Externalizable的区别

Serializable只用来标识一个类是可序列化的，但是序列化操作是由jvm实现的，程序员不能控制，而Externalizable不但是可序列的标识（继承了Serializable），还可以自定义序列化操作（因为接口里有两个方法）

### RPC 不同序列化协议的优缺点

| 优点               | 缺点                                     |                                                              |
| ------------------ | ---------------------------------------- | ------------------------------------------------------------ |
| Kryo               | 速度快，序列化后体积小                   | 跨语言支持较复杂                                             |
| Hessian            | 默认支持跨语言                           | 较慢                                                         |
| Protostuff         | 速度快，基于protobuf                     | 需静态编译                                                   |
| Protostuff-Runtime | 无需静态编译，但序列化前需预先传入schema | 不支持无默认构造函数的类，反序列化时需用户自己初始化序列化后的对象，其只负责将该对象进行赋值 |
| Java               | 使用方便，可序列化所有类                 | 速度慢，占空间                                               |

### 各种序列号协议的特点

详见：<https://blog.csdn.net/qq_38685503/article/details/114633168?spm=1001.2014.3001.5501>

### 为什么选KRYO序列化

因为Kryo序列化速度快，序列化之后体积小

### 各种序列化方式的原理



### 自定义的协议头里包括哪些内容

魔数、包类型，序列化方式、包长度

## 服务注册中心



## 负载均衡

### 什么是负载均衡

指将工作任务分摊到多个节点上进行运行

比如轮询负载均衡算法，就是将任务按照节点的顺序逐个分配

### 有哪些负载均衡算法

随机算法、轮询算法、最少活跃调用数、一致性哈希

#### 原理

**随机算法：**就是随机选择一个结点，但是有时候结点是有权重的，这时候可以把权重加起来，然后随机选择0-权重和之间的数，然后再根据这个数进行选择

**轮询算法：**就是依次的调用所有的结点

**最少活跃算法：**就是每个结点都维护一个计数器，每次一个请求交给它处理时，计数器加一，请求处理完毕后计数器减一，每次选择计数器最小的那个结点，如果计数器最小的结点有多个，那就随机选择一个

**一致性Hash算法：**就是根据哈希值来确定处理请求的结点，但不是普通的取余哈希，因为取余哈希，如果添加或删除结点的话，改动会比较大，一致性hash是先创建一个环形Hash空间，然后将结点的虚拟结点（一般是ip+port+虚拟结点编号）哈希到环上，然后再把请求哈希到环上，然后根据请求哈希到环上的位置，顺时针往下找，找到的第一个虚拟结点就是要发送的结点，详见：<https://www.cnblogs.com/twoheads/p/10135896.html>

#### 优缺点

**随机算法&轮询算法：**

- 优点：使用简单
- 缺点：不适合机器配置不同的场景

**最少活跃算法：**

- 优点：根据服务器当前的请求处理情况，动态分配；
- 缺点：算法实现相对复杂，需要监控服务器请求连接数；

**一致性hash算法：**

- 优点：当某一台提供者挂时，原本该发往该提供者的请求，基于虚拟节点，平摊到其他提供者，不会引起剧烈变动
- 缺点：实现复杂

### 负载均衡作用

1. 根据集群中每个节点的负载情况将用户请求转发到合适的节点上, 以避免单点压力过大的问题
2. 负载均衡可实现集群高可用及伸缩性

### 负载均衡如何保证健壮性

采用心跳机制检测宕机节点

## HTTP 和 RPC

### RPC 有没有可能会用 HTTP 协议

会，grpc就是用的HTTP协议

### HTTP vs RPC



# 零碎

- 匿名内部类也会生成class文件
- transferTo方法是什么？

是Java提供的零拷贝文件传输函数，需要操作系统的支持，Netty的文件传输就采用了Java的transferTo方法，详见上面`Netty 的零拷贝`的解释

# 待做

- jdk动态代理的反射体现在什么地方？
- 主从多线程模型到底是什么
- Netty的内存池是怎么实现的
- 五种IO模型
- 各种序列化方式的原理

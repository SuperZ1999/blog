---
title: "面试题笔记 背诵版"
date: 2023-03-16T22:54:20+08:00
categories: []
tags: []
description: ""
weight:
slug: ""
draft: false
disableShare: false
cover:
    image: ""
    caption: ""
    alt: ""
    relative: false
---

# 项目

## 一般问题

### 碰到的bug



### 最有技术含量的部分



## 动态代理

见：<https://juejin.cn/post/7011357346018361375>

### jdk动态代理

#### 原理

就是先实现代理接口的方法，生成一个匿名内部类，这个匿名内部类里的操作都是调用InvocationHandler的invoke方法，在invoke方法里完成代理

#### 使用步骤

1. 创建被代理类及接口（JDK代理是接口代理）
2. 创建Handle类实现 InvocationHandler接口 ，重写invoke方法
3. 通过Proxy的newProxyInstance()方法获取代理类对象
4. 通过代理类对象调用被代理类的方法

### cglib动态代理

#### 原理

就是修改需要代理的那个类的字节码，生成该类的子类并重写父类的方法，这个子类的方法都会调用回调函数intercept方法，从而完成代理

#### 使用步骤

1. new Enhancer()
2. 设置需要代理的类
3. 设置回调
4. 创建

#### jdk动态代理和cglib动态代理的区别

1. **原理不同：**JDK动态代理：利用反射机制生成一个实现代理接口的匿名类，在调用具体方法前调用InvokeHandler来处理。
   CGLib动态代理：利用ASM（开源的Java字节码编辑库，操作字节码）开源包，将代理对象类的class文件加载进来，通过修改其字节码生成子类来处理。所以jdk动态代理的方式创建代理对象效率较高，执行效率较低，CGLib创建效率较低，执行效率高。
2. **适用场景不同：**jdk动态代理目标类必须是接口类，cglib代理目标类不需要实现接口，但是不能是final类
3. **机制不同：**jdk动态代理是委托机制，因为代理类里无法直接调用被代理类的方法，所以委托InvocationHandler去调用目标类的方法，cglib动态代理是继承机制，代理类和被代理类是父子关系，所以代理类可以调用被代理类的方法，所以通过回调函数MethodInterceptor调用父类方法执行原始逻辑

### 静态代理

为需要代理的类抽象出一个接口，然后编写代理类实现这个接口，实现接口方法时就可以添加代理的逻辑

缺点：1、每个被代理类都要有一个代理类，代码比较冗余 2、一旦改动被代理类，代理类也得改动

#### 静态代理与动态代理的区别

- 静态代理在编译时就已经实现，编译完成后代理类是一个实际的class文件
- 动态代理是在运行时动态生成的，即编译完成后没有实际的class文件，而是在运行时动态生成的

## Netty

### 什么是Netty

Netty就是Java里NIO的封装，让用户可以很方便的使用Java的非阻塞IO

### Netty跟Java NIO有什么不同，为什么不直接使用JDK NIO类库？

说说NIO有什么缺点吧：

1. NIO的类库和API还是有点复杂，比如Buffer的使用 Selector编写复杂，如果对某个事件注册后，业务代码过于耦合，需要了解很多多线程的知识，熟悉网络编程，面对断连重连、保丢失、粘包等，处理复杂
2. NIO存在BUG，根据网上言论说是selector空轮训导致CPU飙升

Netty主要的优点有：

1. 统一的 API，支持多种传输类型，阻塞和非阻塞的。
2. 简单而强大的线程模型。
3. 自带编解码器解决 TCP 粘包/拆包问题，自带各种协议栈。
5. 比直接使用 Java 核心 API 有更高的吞吐量、更低的延迟、更低的资源消耗和更少的内存复制。
7. 社区活跃，成熟稳定，经历了大型项目的使用和考验，而且很多开源项目都使用到了 Netty， 比如我们经常接触的 Dubbo、RocketMQ 等等。

### Netty 应用场景了解么？

理论上来说，NIO 可以做的事情 ，使用 Netty 都可以做并且更好。Netty 主要用来做**网络通信**：

1. **作为 RPC 框架的网络通信工具** 
2. **实现一个自己的 HTTP 服务器** 
3. **实现一个即时通讯系统** 
4. **实现消息推送系统** 

基本只要是网络通信的都可以用Netty做

### Netty的核心组件

#### EventLoop

EventLoop 的主要作用实际就是负责监听网络事件并调用事件处理器进行相关 I/O 操作的处理。

#### Channel

**Channel** 接口是 **Netty** 对网络操作抽象类，它除了包括基本的 **I/O** 操作，如 **bind()**、**connect()**、**read()**、**write()** 等。

比较常用的**Channel**接口实现类是**NioServerSocketChannel**（服务端）和**NioSocketChannel**（客户端），这两个 **Channel** 可以和 **BIO** 编程模型中的**ServerSocket**以及**Socket**两个概念对应上。**Netty** 的 **Channel** 接口所提供的 **API**，大大地降低了直接使用 **Socket** 类的复杂性。

#### ChannelFuture

**Netty** 是异步非阻塞的，所有的 I/O 操作都为异步的。所以我们不能立刻得到操作的结果，我们可以通过 **ChannelFuture** 接口的 **addListener()** 方法注册一个 **ChannelFutureListener**，当操作执行完后，监听就会自动触发返回结果。

#### ChannelHandler 和 ChannelPipeline

ChannelHandler 用来处理 Channel 上的各种事件，分为入站、出站两种。所有 ChannelHandler 被连在一起了，连在一起形成的链就是 ChannelPipeline

### Bootstrap 和 ServerBootstrap 了解么？

1. Bootstrap是客户端，ServerBootstrap是服务端
2. Bootstrap调用connect连接，ServerBootstrap调用bind开启服务
3. Bootstrap 只需要配置一个EventLoopGroup ,而 ServerBootstrap需要配置两个线程组EventLoopGroup ，一个用于处理连接事件，一个用于处理读写事件。

### Netty的线程模型

Netty通过Reactor模型基于多路复用器接收并处理用户请求，内部实现了两个线程池，boss线程池和work线程池，其中boss线程池的线程负责处理请求的accept事件，当接收到accept事件的请求时，把对应的socket封装到一个NioSocketChannel中，并交给work线程池，其中work线程池负责请求的read和write事件，由对应的Handler处理。

单线程模型：所有I/O操作都由一个线程完成，即多路复用、事件分发和处理都是在一个Reactor线程上完成的。既要接收客户端的连接请求,向服务端发起连接，又要发送/读取请求或应答/响应消息。一个NIO 线程同时处理成百上千的链路，性能上无法支撑，速度慢，若线程进入死循环，整个程序不可用，对于高负载、大并发的应用场景不合适。

多线程模型：有一个NIO 线程（Acceptor） 只负责监听服务端，接收客户端的TCP 连接请求；NIO 线程池负责网络IO 的操作，即消息的读取、解码、编码和发送；1 个NIO 线程可以同时处理N 条链路，但是1 个链路只对应1 个NIO 线程，这是为了防止发生并发操作问题。但在并发百万客户端连接或需要安全认证时，一个Acceptor 线程可能会存在性能不足问题。

主从多线程模型：Acceptor 线程用于绑定监听端口，接收客户端连接，将SocketChannel 从主线程池的Reactor 线程的多路复用器上移除，重新注册到Sub 线程池的线程上，用于处理I/O 的读写等操作，从而保证mainReactor只负责接入认证、握手等操作

#### Reactor模型

建立新连接和处理读写操作分开就是Reactor模型

详见：<https://www.cnblogs.com/coding400/p/10865333.html>

### Netty的执行流程

#### 服务端

1. 创建ServerBootStrap实例
2. 设置并绑定Reactor线程池（线程模型）：EventLoopGroup，EventLoop就是处理所有注册到本线程的Selector上面的Channel
3. 设置并绑定服务端的channel（IO模型）
4. 创建处理网络事件的ChannelPipeline和handler
5. 绑定并启动监听端口
6. 当轮询到准备就绪的channel后，由Reactor线程：NioEventLoop执行pipline中的方法，最终调度并执行channelHandler

#### 客户端

1. 创建BootStrap实例
2. 设置并绑定Reactor线程池（线程模型）：EventLoopGroup，EventLoop就是处理所有注册到本线程的Selector上面的Channel
3. 设置并绑定服务端的channel（IO模型）
4. 创建处理网络事件的ChannelPipeline和handler
5. 发起连接

### TCP 粘包/拆包的原因及解决方法

#### 原因

**粘包：**

1. 应用程序写入数据小于套接字缓冲区大小，网卡将应用多次写入的数据发送到网络上，这将会发生粘包。
2. 接收方法不及时读取套接字缓冲区数据，这将发生粘包。

**拆包：**

1. 应用程序写入的数据大于套接字缓冲区大小，这将会发生拆包。
2. 进行MSS（最大报文长度）大小的TCP分段，当TCP报文长度-TCP头部长度>MSS的时候将发生拆包。

#### 解决办法

1. 发送端给每个数据包添加包首部，首部中应该至少包含数据包的长度，这样接收端在接收到数据后，通过读取包首部的长度字段，便知道每一个数据包的实际长度了。（FixedLengthFrameDecoder）
2. 发送端将每个数据包封装为固定长度（不够的可以通过补0填充），这样接收端每次从接收缓冲区中读取固定长度的数据就自然而然的把每个数据包拆分开来。（DelimiterBasedFrameDecoder）
3. 可以在数据包之间设置边界，如添加特殊符号，这样，接收端通过这个边界就可以将不同的数据包拆分开。（LengthFieldBasedFrameDecoder）
4. 通过自定义协议进行粘包和拆包的处理。（MessageToByteEncoder和ByteToMessageDecoder）

### Netty 长连接、心跳机制

#### 长连接

Netty的长连接其实就是TCP的长连接

TCP 在进行读写之前，server 与 client 之间必须提前建立一个连接。建立连接的过程，需要我们常说的三次握手，释放/关闭连接的话需要四次挥手。这个过程是比较消耗网络资源并且有时间延迟的。

所谓，短连接说的就是 server 端 与 client 端建立连接之后，读写完成之后就关闭掉连接，如果下一次再要互相发送消息，就要重新连接。短连接的优点很明显，就是管理和实现都比较简单，缺点也很明显，每一次的读写都要建立连接必然会带来大量网络资源的消耗，并且连接的建立也需要耗费时间。

长连接说的就是 client 向 server 双方建立连接之后，即使 client 与 server 完成一次读写，它们之间的连接并不会主动关闭，后续的读写操作会继续使用这个连接。长连接的可以省去较多的 TCP 建立和关闭的操作，降低对网络资源的依赖，节约时间。对于频繁请求资源的客户来说，非常适用长连接。

#### 心跳机制

在 TCP 保持长连接的过程中，可能会出现断网等网络异常出现，异常发生的时候， client 与 server 之间如果没有交互的话，他们是无法发现对方已经掉线的。为了解决这个问题, 我们就需要引入 **心跳机制** 。

心跳机制的工作原理是: 在 client 与 server 之间在一定时间内没有数据交互时, 即处于 idle 状态时, 客户端或服务器就会发送一个特殊的数据包给对方, 当接收方收到这个数据报文后, 也立即发送一个特殊的数据报文, 回应发送方, 此即一个 PING-PONG 交互。所以, 当某一端收到心跳消息后, 就知道了对方仍然在线, 这就确保 TCP 连接的有效性.

TCP 实际上自带的就有长连接选项，本身是也有心跳包机制，也就是 TCP 的选项：SO_KEEPALIVE。但是，TCP 协议层面的长连接灵活性不够。所以，一般情况下我们都是在应用层协议上实现自定义信跳机制的，也就是在 Netty 层面通过编码实现。通过 Netty 实现心跳机制的话，核心类是 IdleStateHandler 。

### Netty 的零拷贝

#### 操作系统的零拷贝

传统意义的拷贝是在发送数据的时候， 传统的实现方式是：

\1. File.read(bytes)

\2. Socket.send(bytes)

这种方式需要四次数据拷贝和四次上下文切换：

\1. 数据从磁盘读取到内核的read buffer

\2. 数据从内核缓冲区拷贝到用户缓冲区

\3. 数据从用户缓冲区拷贝到内核的socket buffer

\4. 数据从内核的socket buffer拷贝到网卡接口（硬件）的缓冲区

零拷贝的概念明显上面的第二步和第三步是没有必要的，通过java的FileChannel.transferTo方法，可以避免上面两次多余的拷贝（当然这需要底层操作系统支持）

\1. 调用transferTo,数据从文件由DMA引擎拷贝到内核read buffer

\2. 接着DMA从内核read buffer将数据拷贝到网卡接口buffer上面的两次操作都不需要CPU参与，所以就达到了零拷贝。

#### Netty 的零拷贝

Netty 的零拷贝主要包含三个方面：

1. Netty 的接收和发送 ByteBuffer 采用 DIRECT BUFFERS，使用堆外直接内存（注意直接内存可以内核态的缓冲区内存进行内存映射，也就是mmap）进行 Socket 读写，不需要进行字节缓冲区的二次拷贝。如果使用传统的堆内存（HEAP BUFFERS）进行 Socket 读写，JVM 会将堆内存 Buffer 拷贝一份到直接内存中，然后才写入 Socket 中。相比于堆外直接内存，消息在发送过程中多了一次缓冲区的内存拷贝。
2. Netty 提供了组合 Buffer 对象，可以聚合多个 ByteBuffer 对象，用户可以像操作一个 Buffer 那样方便的对组合 Buffer 进行操作，避免了传统通过内存拷贝的方式将几个小 Buffer 合并成一个大的 Buffer。
3. Netty 的文件传输采用了 transferTo 方法，它可以直接将文件缓冲区的数据发送到目标 Channel，避免了传统通过循环 write 方式导致的内存拷贝问题。

### NIO的空轮询bug

#### 原因

若Selector的轮询结果为空，也没有wakeup或新消息处理，则发生空轮询，CPU使用率100%

#### 解决方案

1. 对Selector的select操作周期进行统计，每完成一次空的select操作进行一次计数，
2. 若在某个周期内连续发生N次空轮询，则触发了epoll死循环bug。
3. 重建Selector，判断是否是其他线程发起的重建请求，若不是则将原SocketChannel从旧的Selector上去除注册，重新注册到新的Selector上，并将原来的Selector关闭。

### Netty 高性能表现在哪些方面

1. **IO 线程模型：**使用IO多路复用（同步非阻塞），用最少的资源做更多的事。
2. **零拷贝技术：**尽量减少不必要的内存拷贝，实现了更高效率的传输。
3. **内存池设计：**申请的内存可以重用，主要指直接内存。内部实现是用一颗二叉查找树管理内存分配情况。
4. **串形化处理读写：**避免使用锁带来的性能开销。即消息的处理尽可能在同一个线程内完成，期间不进行线程切换，这样就避免了多线程竞争和同步锁。表面上看，串行化设计似乎CPU利用率不高，并发程度不够。但是，通过调整NIO线程池的线程参数，可以同时启动多个串行化的线程并行运行，这种局部无锁化的串行线程设计相比一个队列-多个工作线程模型性能更优（这种串形化处理读写的设计相当于每个线程都有一个任务队列，使用时不用加锁，所以性能较高）。
5. **高性能序列化协议：**支持 protobuf 等高性能序列化协议。
6. **高效并发编程：**volatile的大量使用；CAS和原子类的广泛使用。

### Netty的内存池是怎么实现的

有点复杂

1. 首先会预申请一大块内存Arena，Arena由许多Chunk组成，而每个Chunk默认由2048个page组成。
2. Chunk通过AVL树的形式组织Page，每个叶子节点表示一个Page，而中间节点表示内存区域，节点自己记录它在整个Arena中的偏移地址。
3. 当区域被分配出去后，中间节点上的标记位会被标记，这样就表示这个中间节点以下的所有节点都已被分配了。

### 五种IO模型

阻塞IO、非阻塞IO、IO多路复用、信号驱动IO，异步IO

#### 同步与异步、阻塞与非阻塞

同步和异步描述的是消息通信的机制。

假如A调用B

同步：A发送request，B返回A需要的response

异步：A发送request，B马上返回空的response或者不返回，B操作完成后，调用A的callback或者给A发信号，将A需要的数据返回给B

阻塞和非阻塞描述的是程序在等待调用结果（消息，返回值）时的状态。

阻塞：阻塞调用是指调用方发出request的线程因为某种原因（如：等待系统资源）被服务方挂起，当服务方得到response后就唤醒挂起线程，并将response返回给调用方。

非阻塞：非阻塞调用是指调用方发出request的线程在没有等到结果时不会被挂起，直到得到response后才返回。

### BIO、NIO、AIO分别是什么？

BIO:同步并阻塞 ，服务器实现模式为一个连接一个线程，即客户端有连接请求时服务器端就需要启动一个线程进行处理，如果这个连接不做任何事情会造成不必要的线程开销，当然可以通过线程池机制改善。BIO方式适用于连接数目比较小且固定的架构，这种方式对服务器资源要求比较高

NIO:同步非阻塞 ，服务器实现模式为一个请求一个线程，即客户端发送的连接请求都会注册到多路复用器上，多路复用器轮询到连接有I/O请求时才启动一个线程进行处理。NIO方式适用于连接数目多且连接比较短（轻操作）的架构，比如聊天服务器

AIO:异步非阻塞 ，服务器实现模式为一个有效请求一个线程，客户端的I/O请求服务器处理之前就会返回，处理完成之后会调用回调函数来返回数据

### select、poll、epoll的机制及其区别？

1. 单个进程打开的文件描述符（fd文件句柄）不一致

select ：有最大连接数限制数为1024，单个进程所能打开的最大连接数由FD_ZETSIZE宏定义。

poll：poll本质上与select没有区别，但是它没有最大连接数的限制，原因是它是基于链表来存储的。

epoll：虽然连接有上限，但是很大，1G内存的机器可以打开10万左右的连接，以此类推。

2. 监听Socket的方式不一致

select ：轮询的方式，一个一个的socket检查过去，发现有socket活跃时才进行处理，当线性socket增多时，轮询的速度将会变得很慢，造成线性造成性能下降问题。

poll：对select稍微进行了优化，只是修改了文件描述符，但是监听socket的方式还是轮询。

epoll：epoll内核中实现是根据每个fd上的callback函数来实现的，只有活跃的socket才会主动调用callback，通知expoll来处理这个socket。（会将连接的socket注册到epoll中, 相当于socket的花名册, 如果有一个socket活跃了, 会回调一个函数, 通知epoll,赶紧过来处理）

select、poll、epoll时间复杂度分别是：O(n)、O(n)、O(1)

3. 内存空间拷贝方式（消息传递方式）不一致

select：内核想将消息传递到用户态，需要将数据从内核态拷贝到用户态,这个过程非常的耗时

poll：同上

epoll：epoll的内核和用户空间共享一块内存，因此内存态数据和用户态数据是共享的

### Netty底层用的什么？

Java层面用的NIO的Selector机制，操作系统层面Linux用的epoll，Windows用的IOCP

## 序列化

### 序列化和反序列化有什么作用

1. **实现了数据的持久化**：永久性保存对象，保存对象的字节序列到本地文件或者数据库中
2. **序列化实现远程通**：通过序列化以字节流的形式使对象在网络中进行传递和接收
3. 通过序列化在进程间传递对象

### Serializable接口的作用

其实Serializable接口只是一个标识，序列化由ObjectInputStream和ObjectOutputStream执行，具体操作在jvm里

#### Serializable和Externalizable的区别

Serializable只用来标识一个类是可序列化的，但是序列化操作是由jvm实现的，程序员不能控制，而Externalizable不但是可序列的标识（继承了Serializable），还可以自定义序列化操作（因为接口里有两个方法）

### RPC 不同序列化协议的优缺点

| 优点               | 缺点                                     |                                                              |
| ------------------ | ---------------------------------------- | ------------------------------------------------------------ |
| Kryo               | 速度快，序列化后体积小                   | 跨语言支持较复杂                                             |
| Hessian            | 默认支持跨语言                           | 较慢                                                         |
| Protostuff         | 速度快，基于protobuf                     | 需静态编译                                                   |
| Protostuff-Runtime | 无需静态编译，但序列化前需预先传入schema | 不支持无默认构造函数的类，反序列化时需用户自己初始化序列化后的对象，其只负责将该对象进行赋值 |
| Java               | 使用方便，可序列化所有类                 | 速度慢，占空间                                               |

### 各种序列化协议的特点

详见：<https://blog.csdn.net/qq_38685503/article/details/114633168?spm=1001.2014.3001.5501>

### 为什么选KRYO序列化

因为Kryo序列化速度快，序列化之后体积小

### 各种序列化方式的原理



### 自定义的协议头里包括哪些内容

魔数、包类型，序列化方式、包长度

## 服务注册中心



## 负载均衡

### 什么是负载均衡

指将工作任务分摊到多个节点上进行运行

比如轮询负载均衡算法，就是将任务按照节点的顺序逐个分配

### 有哪些负载均衡算法

随机算法、轮询算法、最少活跃调用数、一致性哈希

#### 原理

**随机算法：**就是随机选择一个结点，但是有时候结点是有权重的，这时候可以把权重加起来，然后随机选择0-权重和之间的数，然后再根据这个数进行选择

**轮询算法：**就是依次的调用所有的结点

**最少活跃算法：**就是每个结点都维护一个计数器，每次一个请求交给它处理时，计数器加一，请求处理完毕后计数器减一，每次选择计数器最小的那个结点，如果计数器最小的结点有多个，那就随机选择一个

**一致性Hash算法：**就是根据哈希值来确定处理请求的结点，但不是普通的取余哈希，因为取余哈希，如果添加或删除结点的话，改动会比较大，一致性hash是先创建一个环形Hash空间，然后将结点的虚拟结点（一般是ip+port+虚拟结点编号）哈希到环上，然后再把请求哈希到环上，然后根据请求哈希到环上的位置，顺时针往下找，找到的第一个虚拟结点就是要发送的结点，详见：<https://www.cnblogs.com/twoheads/p/10135896.html>

#### 优缺点

**随机算法&轮询算法：**

- 优点：使用简单
- 缺点：不适合机器配置不同的场景

**最少活跃算法：**

- 优点：根据服务器当前的请求处理情况，动态分配；
- 缺点：算法实现相对复杂，需要监控服务器请求连接数；

**一致性hash算法：**

- 优点：当某一台提供者挂时，原本该发往该提供者的请求，基于虚拟节点，平摊到其他提供者，不会引起剧烈变动
- 缺点：实现复杂

### 负载均衡作用

1. 根据集群中每个节点的负载情况将用户请求转发到合适的节点上, 以避免单点压力过大的问题
2. 负载均衡可实现集群高可用及伸缩性

### 负载均衡如何保证健壮性

采用心跳机制检测宕机节点

## HTTP 和 RPC

### RPC 有没有可能会用 HTTP 协议

会，grpc就是用的HTTP协议

### HTTP vs RPC

#### 相同点

都可以完成远程调用

#### 不同点

1. 传输协议
   - RPC：可以基于TCP协议，也可以基于HTTP协议。
   - HTTP：基于HTTP协议。

2. 传输效率

   - RPC：基于TCP可以自定义应用层协议，可以让请求报文体积更小，提高传输效率

   - HTTP：如果时基于HTTP1.1的协议，请求中会包含很多无用的内容，很臃肿

3. 性能消耗

   - RPC：序列化时可以选择二进制序列化方式

   - HTTP：一般序列化都是json方式，体积和序列化耗时都比二进制序列化要更消耗性能

4. 负载均衡

   - RPC：基本都自带了负载均衡策略

   - HTTP：需要配置Nginx实现

5. 服务治理
   - RPC：能做到自动通知，不影响上游
   - HTTP：需要事先通知，修改Nginx配置

#### 使用场景

- 如果对**效率**要求更高，并且开发过程使用**统一的技术栈**，那么可以用RPC
- 如果需要更加**灵活**，**跨语言**、**跨平台**，HTTP更合适

## Nacos

### Nacos vs Zookeeper vs Eureka

![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/cec3502b6246497ebb0e3bd18eab0ffa~tplv-k3u1fbpfcp-zoom-in-crop-mark:4536:0:0:0.awebp)

### CAP理论

CAP理论是分布式架构中重要理论：

- 一致性(Consistency)：所有节点在同一时间具有相同的数据；
- 可用性(Availability) ：保证每个请求不管成功或者失败都有响应；
- 分隔容忍(Partition tolerance) ：系统中任意信息的丢失或失败不会影响系统的继续运作。

CAP不最多能保证两个，不能都保证，原因不清楚

Nacos可以保证AP或者CP

### 为什么选择Nacos

因为Eureka已经停止维护了，zookeeper本质上是个文件系统，使用起来比较麻烦，所以选择了Nacos

### Nacos服务注册表结构是什么样的？

Nacos最外层是namespace隔离环境，然后是group对服务进行分组，然后就是服务，一个服务下 有多个集群，集群下有多个实例。
对应Java代码，`Map<String,Map<String,Service>>`，最外层的key是namespaceId，值是map，内部map大的key是group拼接serviceName（group@@serviceName），值是service对象；
service对象内部又是一个map，key是集群名称，值是Cluster对象，Cluster对象内部维护了实例对象集合。

![在这里插入图片描述](https://img-blog.csdnimg.cn/3d7ad21f0a6040cdaa09563a932f55d3.png)

### Nacos配置中心宕机，还能读取到配置吗

可以，客户端读取到配置信息以后会缓存在本地内存，因此可以在内存中拿到数据。

### 服务提供者如何向Nacos注册中心续约

利用心跳机制，如果注册中心发现服务结点还活着就会续约

### 如何确定实例状态

通过发送心跳包，5秒发送一次，如果15秒没有回应，则说明服务出现了问题，
如果30秒后没有回应，则说明服务已经停止。

### 为什么要使用配置中心

因为用配置中心可以很好的管理项目配置，比如修改配置，不用每个结点都修改一次，而且用配置中心可以动态发布配置

# 网络

## 基础

### OSI 和 TCP/IP 网络分层模型

#### OSI 七层模型是什么？每一层的作用是什么？

![OSI 七层模型](https://guide-blog-images.oss-cn-shenzhen.aliyuncs.com/github/javaguide/cs-basics/network/osi-7-model.png)

#### TCP/IP 四层模型是什么？每一层的作用是什么？

- 应用层：**应用层位于传输层之上，主要提供两个终端设备上的应用程序之间信息交换的服务，它定义了信息交换的格式，消息会交给下一层传输层来传输。**
- 传输层：**传输层的主要任务就是负责向两台终端设备进程之间的通信提供通用的数据传输服务。**
- 网络层：**网络层负责为网上的不同主机之间提供通信服务。**
- 网络接口层：可以看做是数据链路层和物理层的合体
  - 数据链路层：**数据链路层的作用是将网络层交下来的 IP 数据报组装成帧，在两个相邻节点间的链路上传送帧。每一帧包括数据和必要的控制信息（如同步信息，地址信息，差错控制等）。**
  - 物理层：**实现相邻计算机节点之间比特流的透明传送，尽可能向上屏蔽掉具体传输介质和物理设备的差异**

### 为什么网络要分层？

跟开发程序时的高内聚低耦合思想很接近

1. **各层之间相互独立**，不需要关心其他层是怎么是实现的，只需要知道怎么调用下层提供的接口就行
2. **提高了整体灵活性**，每一层都可以使用最适合的技术来实现，只需要提供规范的接口就可以，比较灵活
3. **大问题化小**，可以降低系统的复杂度

### 应用层有哪些常见的协议？

HTTP、SMTP、POP3/IMAP、FTP、Telnet、SSH

#### HTTP（超文本传输协议）

1. 主要是为 Web 浏览器与 Web 服务器之间的通信而设计的，访问网页的时候用的就是http协议。

2. HTTP 协基于 TCP协议，目前使用的 HTTP 协议大部分都是 1.1。在 1.1 的协议里面，默认是开启了 Keep-Alive 的，这样的话建立的连接就可以在多次请求中被复用了。

3. 另外， HTTP 协议是”无状态”的协议，它无法记录客户端用户的状态，一般我们都是通过 Session 来记录客户端用户的状态。

#### SMTP（简单邮件传输(发送)协议）

基于 TCP 协议，用来发送电子邮件。

##### 电子邮件的发送过程？

1. 通过SMTP协议把邮件发送到我的邮件服务器
2. 我的邮件服务器通过SMTP协议在互联网上发送给对方的邮件服务器
3. 对方的邮件服务器通知对方来取，对方使用POP3协议取走

##### 如何判断邮箱是真正存在的？

1. 查找邮箱域名对应的 SMTP 服务器地址
2. 尝试与服务器建立连接
3. 连接成功后尝试向需要验证的邮箱发送邮件
4. 根据返回结果判定邮箱地址的真实性

#### POP3/IMAP（邮件接收的协议）

1. POP3 和 IMAP 两者都是负责邮件接收的协议
2. SMTP 协议只负责邮件的发送，真正负责接收的协议是POP3/IMAP
3. IMAP相当于POP3的升级版

#### FTP（文件传输协议）

1. 基于 TCP 实现可靠的传输
2. 两条tcp连接，21端口的用于控制，20端口用于传输数据

#### Telnet（远程登陆协议）

建立在可靠的传输协议 TCP 之上，但是传输的数据都是明文，很不安全，所以被SSH取代

#### SSH（安全的网络传输协议）

建立在可靠的传输协议 TCP 之上

##### Telnet 和 SSH 之间的主要区别？

 SSH 协议会对传输的数据进行加密保证数据安全性。

## TCP和UDP

### TCP 与 UDP 的区别？（重要）

简化版：

1. **是否面向连接** ：TCP是面向连接的，UDP是面向无连接的

2. **是否是可靠传输**：TCP是可靠的，UDP是不可靠的

3. **是否有状态** ：TCP是有状态的，比如会记录发送了那些数据，接受了哪些数据，UDP是无状态的

4. **传输效率** ：由于使用 TCP 进行传输的时候多了连接、确认、重传等机制，所以 TCP 的传输效率要比 UDP 低很多。

5. **传输形式** ： TCP 是面向字节流的，UDP 是面向报文的。

6. **首部开销** ：TCP 首部开销（20 ～ 60 字节）比 UDP 首部开销（8 字节）要大。

7. **是否提供广播或多播服务** ：TCP 只支持点对点通信，UDP 支持一对一、一对多、多对一、多对多。

详细版：

1. **是否面向连接** ：UDP 在传送数据之前不需要先建立连接。而 TCP 提供面向连接的服务，在传送数据之前必须先建立连接，数据传送结束后要释放连接。

2. **是否是可靠传输**：远地主机在收到 UDP 报文后，不需要给出任何确认，并且不保证数据不丢失，不保证是否顺序到达。TCP 提供可靠的传输服务，TCP 在传递数据之前，会有三次握手来建立连接，而且在数据传递时，有确认、窗口、重传、拥塞控制机制。通过 TCP 连接传输的数据，无差错、不丢失、不重复、并且按序到达。

3. **是否有状态** ：这个和上面的“是否可靠传输”相对应。TCP 传输是有状态的，这个有状态说的是 TCP 会去记录自己发送消息的状态比如消息是否发送了、是否被接收了等等。为此 ，TCP 需要维持复杂的连接状态表。而 UDP 是无状态服务，简单来说就是不管发出去之后的事情了（**这很渣男！**）。

4. **传输效率** ：由于使用 TCP 进行传输的时候多了连接、确认、重传等机制，所以 TCP 的传输效率要比 UDP 低很多。

5. **传输形式** ： TCP 是面向字节流的，UDP 是面向报文的。

6. **首部开销** ：TCP 首部开销（20 ～ 60 字节）比 UDP 首部开销（8 字节）要大。

7. **是否提供广播或多播服务** ：TCP 只支持点对点通信，UDP 支持一对一、一对多、多对一、多对多。

表格版：

| TCP                    | UDP            |            |
| ---------------------- | -------------- | ---------- |
| 是否面向连接           | 是             | 否         |
| 是否可靠               | 是             | 否         |
| 是否有状态             | 是             | 否         |
| 传输效率               | 较慢           | 较快       |
| 传输形式               | 字节流         | 数据报文段 |
| 首部开销               | 20 ～ 60 bytes | 8 bytes    |
| 是否提供广播或多播服务 | 否             | 是         |

### 什么时候选择 TCP,什么时候选 UDP?

- **UDP 一般用于即时通信**

- **TCP 用于对传输准确性要求特别高的场景**

### HTTP 基于 TCP 还是 UDP？

HTTP3.0之前基于TCP，3.0之后基于基于UDP的QUIC协议，目的是为了解决队头阻塞

#### 队头阻塞

HTTP1.1的队头阻塞是因为1.1是一问一答模式，所以当一个大的响应没回来的时候，其他请求都要等待

HTTP2.0使用了多路复用，就是一个HTTP连接上可以同时发送多个HTTP请求，解决了1.1的对头阻塞，但是只解决了应用层的队头阻塞，传输层依然有队头阻塞，因为如果发送3个包，第一个包丢了，那么服务端为了保证有序接受就会等待直到接收到1，但是http包都是独立的，这个时候完全可以处理2和3包，这就是HTTP2.0的队头阻塞

HTTP3.0为了解决2.0的队头阻塞使用了基于UDP的QUIC协议

### 使用 TCP 的协议有哪些？

- **HTTP 协议** ：超文本传输协议（HTTP，HyperText Transfer Protocol)主要是为 Web 浏览器与 Web 服务器之间的通信而设计的。当我们使用浏览器浏览网页的时候，我们网页就是通过 HTTP 请求进行加载的。

- **HTTPS 协议** ：更安全的超文本传输协议(HTTPS,Hypertext Transfer Protocol Secure)，身披 SSL 外衣的 HTTP 协议

- **FTP 协议**：文件传输协议 FTP（File Transfer Protocol），提供文件传输服务，**基于 TCP** 实现可靠的传输。使用 FTP 传输文件的好处是可以屏蔽操作系统和文件存储方式。

- **SMTP 协议**：简单邮件传输协议（SMTP，Simple Mail Transfer Protocol）的缩写，**基于 TCP 协议**，用来发送电子邮件。注意 ⚠️：接受邮件的协议不是 SMTP 而是 POP3 协议。

- **POP3/IMAP 协议**： POP3 和 IMAP 两者都是负责邮件接收的协议。

- **Telnet 协议**：远程登陆协议，通过一个终端登陆到其他服务器。被一种称为 SSH 的非常安全的协议所取代。

- **SSH 协议** : SSH（ Secure Shell）是目前较可靠，专为远程登录会话和其他网络服务提供安全性的协议。利用 SSH 协议可以有效防止远程管理过程中的信息泄露问题。SSH 建立在可靠的传输协议 TCP 之上。

### 使用 UDP 的协议有哪些？

- **DHCP 协议**：动态主机配置协议，动态配置 IP 地址

- **DNS** ： **域名系统（DNS，Domain Name System）将人类可读的域名 (例如，www.baidu.com) 转换为机器可读的 IP 地址 (例如，220.181.38.148)。** 我们可以将其理解为专为互联网设计的电话薄。实际上 DNS 同时支持 UDP 和 TCP 协议。

### TCP 三次握手和四次挥手（非常重要）

详见：<https://javaguide.cn/cs-basics/network/tcp-connection-and-disconnection.html>

![img](https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/e92d0ebc-7d46-413b-aec1-34a39602f787.png)

![img](https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/f87afe72-c2df-4c12-ac03-9b8d581a8af8.jpg)

#### 为什么要三次握手？

三次握手的目的是建立可靠的通信信道，那三次握手是怎么建立起可靠的通信通道的呢？

- **第一次握手** ：Client不能确保对方收到了自己的请求

- **第二次握手** ：Server不能确保对方收到了自己的回应

- **第三次握手** ：双方都能确保对方收到了自己的请求

#### 第2次握手传回了ACK，为什么还要传回SYN？

回传ACK代表收到了对方的信息，回传SYN代表同意连接

#### 为什么要四次挥手？

因为通信双方都能收发数据，所以必须保证两者都没有数据要发送的时候才能断开连接，那四次挥手是怎么保证的呢？

- **第一次挥手** ：只能保证A没有信息发送了，但是B可能还有信息待发送

- **第二次挥手** ：只是让A知道B收到了断开连接请求，但是这个时候B有可能还有信息没有发完

- **第三次挥手** ：可以保证A和B都没有信息发送了，但是如果第三次挥手包丢了的话无法保证A知道B发送完了

- **第四次挥手** ：可以保证A和B都没有信息发送了，并且A知道B发送完了，B也知道A接收到了自己发送完的信息

#### 为什么不能把服务器发送的 ACK 和 FIN 合并起来，变成三次挥手？

因为服务器收到客户端断开连接的请求时，可能还有一些数据没有发完，这时先回复 ACK，表示接收到了断开连接的请求。等到数据发完之后再发 FIN，断开服务器到客户端的数据传送。

#### 如果第二次挥手时服务器的 ACK 没有送达客户端，会怎样？

客户端没有收到 ACK 确认，会重新发送 FIN 请求。

#### 为什么第四次挥手客户端需要等待 2*MSL（报文段最长寿命）时间后才进入 CLOSED 状态？

防止 Server 未收到 ACK

解释：第四次挥手时，客户端发送给服务器的 ACK 有可能丢失，如果服务端因为某些原因而没有收到 ACK 的话，服务端就会重发 FIN，如果客户端在 2*MSL 的时间内收到了 FIN，就会重新发送 ACK 并再次等待 2MSL，防止 Server 没有收到 ACK 而不断重发 FIN。

##### 为什么是2*MSL呢

因为加入第四次挥手的包在第一个MSL丢失，那么重发的第三次挥手的包一定在第二个MSL到达

### TCP 如何保证传输的可靠性？

**精简版：**

- **基于数据块传输** ：应用数据被分割成数据块，再传输给网络层

- **对失序数据包重新排序以及去重**：TCP 为了保证不发生丢包，就给每个包一个序列号，有了序列号就可以对包进行排序和去重了

- **校验和** : TCP 将保持它报文的检验和。如果收到段的检验和有差错，TCP 将丢弃这个报文段

- **超时重传** : 当发送方发送数据之后，如果一段时间之后没有收到这个包的回应就会重传

- **流量控制** : 如果接收端来不及处理接收到的数据，就会提示发送方降低速率，起到流量控制的效果，具体是使用滑动窗口来实现的

- **拥塞控制** : 当网络拥塞时，减少数据的发送。

**详细版：**

- **基于数据块传输** ：应用数据被分割成 TCP 认为最适合发送的数据块，再传输给网络层，数据块被称为报文段或段。

- **对失序数据包重新排序以及去重**：TCP 为了保证不发生丢包，就给每个包一个序列号，有了序列号能够将接收到的数据根据序列号排序，并且去掉重复序列号的数据就可以实现数据包去重。

- **校验和** : TCP 将保持它首部和数据的检验和。这是一个端到端的检验和，目的是检测数据在传输过程中的任何变化。如果收到段的检验和有差错，TCP 将丢弃这个报文段和不确认收到此报文段。

- **超时重传** : 当发送方发送数据之后，它启动一个定时器，等待目的端确认收到这个报文段。接收端实体对已成功收到的包发回一个相应的确认信息（ACK）。如果发送端实体在合理的往返时延（RTT）内未收到确认消息，那么对应的数据包就被假设为[已丢失open in new window](https://zh.wikipedia.org/wiki/丢包)并进行重传。

- **流量控制** : TCP 连接的每一方都有固定大小的缓冲空间，TCP 的接收端只允许发送端发送接收端缓冲区能接纳的数据。当接收方来不及处理发送方的数据，能提示发送方降低发送的速率，防止包丢失。TCP 使用的流量控制协议是可变大小的滑动窗口协议（TCP 利用滑动窗口实现流量控制）。

- **拥塞控制** : 当网络拥塞时，减少数据的发送。

#### TCP 如何实现流量控制？

**TCP 利用滑动窗口实现流量控制。** 接收方发送的确认报文中的窗口字段可以用来控制发送方窗口大小，从而影响发送方的发送速率。将窗口字段设置为 0，则发送方不能发送数据。

##### 为什么需要流量控制？

因为发送方的速率与接收方的速率是不一定相等，如果发送方的速率大于接受方的速率，就会导致接受方丢掉处理不过来的包

##### 滑动窗口是什么？

就是发送端和接收端各有一个窗口，发送窗口里是可以发送的报文，接受窗口里是可以接受的报文，如果发送窗口收到回应之后就会向前滑动知道碰到没收到回应的那个窗口，接收窗口同理

见：<https://javaguide.cn/cs-basics/network/tcp-reliability-guarantee.html>

#### TCP 如何实现拥塞控制？

主要就是通过四个算法实现的拥塞控制：

1. 慢启动：当TCP开始发送数据时，它会先发送一小部分数据，然后每次乘2逐渐扩大拥塞窗口
2. 拥塞避免：一旦慢启动进入拥塞避免阶段，那么拥塞窗口就会从每次乘2变成每次加1
3. 快重传：
4. 快恢复：

见：<https://javaguide.cn/cs-basics/network/tcp-reliability-guarantee.html>

#### ARQ 协议是什么

就是自动重传请求协议，包括停止等待 ARQ 协议和连续 ARQ 协议。

ARQ协议也用到了滑动窗口，和流量控制里面的滑动窗口的区别是流量控制在传输层，ARQ协议在传输层和数据链路层。

##### 停止等待 ARQ 协议和连续 ARQ 协议的区别是什么？

停止等待 ARQ 协议，发送并接收到确认消息才发下一个

连续 ARQ 协议，维持一个发送窗口，可以连续发送多个数据包

## HTTP

### 从输入URL 到页面展示到底发生了什么？

![img](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-11/url%E8%BE%93%E5%85%A5%E5%88%B0%E5%B1%95%E7%A4%BA%E5%87%BA%E6%9D%A5%E7%9A%84%E8%BF%87%E7%A8%8B.jpg)

详见：[从输入URL到页面加载发生了什么？](https://segmentfault.com/a/1190000006879700)

[浏览器从输入网址到页面展示的过程](https://cloud.tencent.com/developer/article/1879758)

### HTTP 状态码有哪些？

![状态码](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019/7/%E7%8A%B6%E6%80%81%E7%A0%81.png)

### HTTP 和 HTTPS 有什么区别？（重要）

1. **端口号** ：HTTP 默认是 80，HTTPS 默认是 443。
2. **URL 前缀** ：HTTP 的 URL 前缀是 `http://`，HTTPS 的 URL 前缀是 `https://`。
3. **安全性和资源消耗** ： HTTP 协议运行在 TCP 之上，所有传输的内容都是明文。HTTPS相对于HTTP多了一层SSL加密。所以说，HTTP 安全性没有 HTTPS 高，但是 HTTPS 比 HTTP 耗费更多服务器资源。

### HTTP 1.0 和 HTTP 1.1 有什么区别？

- **默认连接方式 :** HTTP 1.0 默认为短连接，HTTP 1.1 默认为长连接。
- **状态响应码 :** HTTP/1.1中新加入了大量的状态码
- **缓存处理**：HTTP/1.1中新加入了很多缓存头来控制缓存策略
- **带宽优化及网络连接的使用**：HTTP1.0 中，只能发送完成的资源，而HTTP1.1里可以发送部分数据
- **Host头处理** : HTTP/1.1在请求头中加入了`Host`字段。

HTTP 协议的长连接和短连接，实质上是 TCP 协议的长连接和短连接。

### 1.1 vs 2.0 vs 3.0

1.1是收到上一个请求的响应后才能发送下一个请求，这样就产生了队头阻塞问题，而HTTP2.0相对于1.1可以连续发送多个请求，在应用层解决了队头阻塞，但是传输层还是有队头阻塞，3.0使用基于UDP的QUIC协议替代TCP协议解决了传输层的队头阻塞问题

### HTTP 是不保存状态的协议, 如何保存用户状态？

使用session来保存状态，服务端为每个客户端创建一个session，然后将sessionID随响应一起发给客户端，客户端下次发请求带着这个sessionID（放在cookie中），服务端就知道是谁发送的请求了，通过这种方式能保存用户状态

#### Cookie 被禁用怎么办?

最常用的就是利用 URL 重写把 Session ID 直接附加在 URL 路径的后面。注意URL重写指的是服务端将页面响应给客户端之前将里面的URL全部重写，加上Session ID作为参数

### URI 和 URL 的区别是什么？

- URI(Uniform Resource Identifier) 是统一资源标志符，可以唯一标识一个资源。

- URL(Uniform Resource Locator) 是统一资源定位符，不但可以唯一标识一个资源还可以定位这个资源

URI 的作用像身份证号一样，URL 的作用更像家庭住址一样。URL 是一种具体的 URI，它不仅唯一标识资源，而且还提供了定位该资源的信息。

### GET和POST的区别

一般情况下GET是用来获取资源的，参数是放在URL里面，POST是用来处理资源的，参数一般放在请求体里面

### WebSocket vs HTTP

TCP 协议本身是**全双工**的，但是HTTP协议不是全双工的，只能是客户端一问一答模式，服务端不能主动发送信息，为了解决这个问题提出了WebSocket，WebSocket是全双工的，握手阶段使用HTTP协议，握手完成后服务端可以主动发消息到客户端

#### WebSocket

- TCP 协议本身是**全双工**的，但我们最常用的 HTTP/1.1，虽然是基于 TCP 的协议，但它是**半双工**的，对于大部分需要服务器主动推送数据到客户端的场景，都不太友好，因此我们需要使用支持全双工的 WebSocket 协议。
- 在 HTTP/1.1 里，只要客户端不问，服务端就不答。基于这样的特点，对于登录页面这样的简单场景，可以使用**定时轮询或者长轮询**的方式实现**服务器推送**(comet)的效果。
- 对于客户端和服务端之间需要频繁交互的复杂场景，比如网页游戏，都可以考虑使用 WebSocket 协议。
- WebSocket 和 socket 几乎没有任何关系，只是叫法相似。
- 正因为各个浏览器都支持 HTTP协 议，所以 WebSocket 会先利用HTTP协议加上一些特殊的 header 头进行握手升级操作，升级成功后就跟 HTTP 没有任何关系了，之后就用 WebSocket 的数据格式进行收发数据。

## ARP

### 什么是 Mac 地址？

每个网络设备都有一个标识，这个标识就是MAC地址

MAC 地址有一个特殊地址：FF-FF-FF-FF-FF-FF（全 1 地址），该地址表示广播地址。

### ARP 协议解决了什么问题地位如何？

ARP协议就是解决了IP到MAC地址的映射，因为我们在网络上定位一个主机用的是IP地址，但是在传输的时候需要知道下一跳的物理地址，所以就需要IP到MAC的映射

### ARP 协议的工作原理？

详见：<https://javaguide.cn/cs-basics/network/arp.html>

# 操作系统

## 基础

### 什么是操作系统？

- **操作系统（Operating System，简称 OS）是管理计算机硬件与软件资源的程序，是计算机的基石。**

- **操作系统本质上是一个运行在计算机上的软件程序 ，用于管理计算机硬件和软件资源。** 举例：运行在你电脑上的所有应用程序都通过操作系统来调用系统内存以及磁盘等等硬件。

- **操作系统存在屏蔽了硬件层的复杂性。** 操作系统就像是硬件使用的负责人，统筹着各种相关事项。

- **操作系统的内核（Kernel）是操作系统的核心部分，它负责系统的内存管理，硬件设备的管理，文件系统的管理以及应用程序的管理**。 内核是连接应用程序和硬件的桥梁，决定着系统的性能和稳定性。

### 什么是系统调用？

就是系统给用户提供的接口

见：<https://javaguide.cn/cs-basics/operating-system/operating-system-basic-questions-01.html>

## 进程和线程

###  进程和线程的区别？

1. **拥有资源不同**，进程是资源分配的基本单位，但是线程不拥有资源，线程可以访问隶属进程的资源。
2. **调度不同**，线程是独立调度的基本单位，在同一进程中，线程的切换不会引起进程切换，从一个进程中的线程切换到另一个进程中的线程时，会引起进程切换。
3. **系统开销不同**，线程是轻量级进程，在切换或者新建或者撤销的时候线程的开销比进程小
4. **通信方面不同**，线程间可以通过直接读写同一进程中的数据进行通信，但是进程通信需要借助 IPC。

### 进程有哪几种状态？

共5种状态：

- **创建状态(new)** ：进程正在被创建，尚未到就绪状态。

- **就绪状态(ready)** ：进程已处于准备运行状态，即进程获得了除了处理器之外的一切所需资源，一旦得到处理器资源(处理器分配的时间片)即可运行。

- **运行状态(running)** ：进程正在处理器上上运行(单核 CPU 下任意时刻只有一个进程处于运行状态)。

- **阻塞状态(waiting)** ：又称为等待状态，进程正在等待某一事件而暂停运行如等待某资源为可用或等待 IO 操作完成。即使处理器空闲，该进程也不能运行。

- **结束状态(terminated)** ：进程正在从系统中消失。可能是进程正常结束或其他原因中断退出运行。

如图：

![process-state](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-11/d38202593012b457debbcd74994c6292.png)

### 进程间的通信常见的的有哪几种方式？

大概有 7 种常见的进程间的通信方式

- **管道/匿名管道(Pipes)** ：用于具有亲缘关系的父子进程间或者兄弟进程之间的通信。

- **有名管道(Named Pipes)** : 匿名管道由于没有名字，只能用于亲缘关系的进程间通信。为了克服这个缺点，提出了有名管道。有名管道严格遵循**先进先出(first in first out)**。有名管道以磁盘文件的方式存在，可以实现本机任意两个进程通信。

- **信号(Signal)** ：信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生；

- **消息队列(Message Queuing)** ：消息队列是消息的链表,具有特定的格式,存放在内存中并由消息队列标识符标识。管道和消息队列的通信数据都是先进先出的原则。与管道（无名管道：只存在于内存中的文件；命名管道：存在于实际的磁盘介质或者文件系统）不同的是消息队列存放在内核中，只有在内核重启(即，操作系统重启)或者显式地删除一个消息队列时，该消息队列才会被真正的删除。消息队列可以实现消息的随机查询,消息不一定要以先进先出的次序读取,也可以按消息的类型读取.比 FIFO 更有优势。**消息队列克服了信号承载信息量少，管道只能承载无格式字 节流以及缓冲区大小受限等缺点。**

- **信号量(Semaphores)** ：信号量是一个计数器，用于多进程对共享数据的访问，信号量的意图在于进程间同步。这种通信方式主要用于解决与同步相关的问题并避免竞争条件。

- **共享内存(Shared memory)** ：使得多个进程可以访问同一块内存空间，不同进程可以及时看到对方进程中对共享内存中数据的更新。这种方式需要依靠某种同步操作，如互斥锁和信号量等。可以说这是最有用的进程间通信方式。

- **套接字(Sockets)** : 此方法主要用于在客户端和服务器之间通过网络进行通信。套接字是支持 TCP/IP 的网络通信的基本操作单元，可以看做是不同主机之间的进程进行双向通信的端点，简单的说就是通信的两方的一种约定，用套接字中的相关函数来完成通信过程。

### 线程间的同步的方式有哪些呢？

线程同步是两个或多个共享关键资源的线程的并发执行。应该同步线程以避免关键的资源使用冲突。操作系统一般有下面三种线程同步的方式：

1. **互斥量(Mutex)**：采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问。比如 Java 中的 synchronized 关键词和各种 Lock 都是这种机制。
2. **信号量(Semaphore)** ：它允许同一时刻多个线程访问同一资源，但是需要控制同一时刻访问此资源的最大线程数量。
3. **事件(Event)** :Wait/Notify：通过通知操作的方式来保持多线程同步，还可以方便的实现多线程优先级的比较操作。

### 操作系统中进程的调度算法有哪些？

为了确定首先执行哪个进程以及最后执行哪个进程以实现最大 CPU 利用率，计算机科学家已经定义了一些算法，它们是：

- **先到先服务(FCFS)调度算法** : 从就绪队列中选择一个最先进入该队列的进程为之分配资源，使它立即执行并一直执行到完成或发生某事件而被阻塞放弃占用 CPU 时再重新调度。
- **短作业优先(SJF)的调度算法** : 从就绪队列中选出一个估计运行时间最短的进程为之分配资源，使它立即执行并一直执行到完成或发生某事件而被阻塞放弃占用 CPU 时再重新调度。
- **时间片轮转调度算法** : 时间片轮转调度是一种最古老，最简单，最公平且使用最广的算法，又称 RR(Round robin)调度。每个进程被分配一个时间段，称作它的时间片，即该进程允许运行的时间。
- **多级反馈队列调度算法** ：前面介绍的几种进程调度的算法都有一定的局限性。如**短进程优先的调度算法，仅照顾了短进程而忽略了长进程** 。多级反馈队列调度算法既能使高优先级的作业得到响应又能使短作业（进程）迅速完成。，因而它是目前**被公认的一种较好的进程调度算法**，UNIX 操作系统采取的便是这种调度算法。
- **优先级调度** ： 为每个流程分配优先级，首先执行具有最高优先级的进程，依此类推。具有相同优先级的进程以 FCFS 方式执行。可以根据内存要求，时间要求或任何其他资源要求来确定优先级。

### 什么是死锁？

死锁是指两个或两个以上的进程在执行过程中，由于竞争资源而循环等待的这种现象，若无外力作用，它们都将无法推进下去

### 产生死锁的四个必要条件是什么？

- **互斥**：资源必须处于非共享模式，即一次只有一个进程可以使用。如果另一进程申请该资源，那么必须等待直到该资源被释放为止。

- **占有并等待**：一个进程至少应该占有一个资源，并等待另一资源，而该资源被其他进程所占有。

- **不可剥夺**：资源不能被抢占。只能在持有资源的进程完成任务后，该资源才会被释放。

- **循环等待**：有一组等待进程 `{P0, P1, P2}`， `P0` 等待的资源被 `P1` 占有，`P1` 等待的资源被 `P2` 占有，`P2` 等待的资源被 `P0` 占有。

### 怎么解决死锁？

解决死锁的方法可以从多个角度去分析，一般的情况下，有**预防，避免，检测和解除四种**。

- **预防** 是采用某种策略，**限制并发进程对资源的请求**，从而使得死锁的必要条件在系统执行的任何时间上都不满足。
- **避免**则是系统在分配资源时，根据资源的使用情况**提前做出预测**，从而**避免死锁的发生**
- **检测**是指系统设有**专门的机构**，当死锁发生时，该机构能够检测死锁的发生，并精确地确定与死锁有关的进程和资源。
- **解除** 是与检测相配套的一种措施，用于**将进程从死锁状态下解脱出来**。

#### 死锁如何预防？

**破坏** 死锁产生的四个必要条件之一就可以成功 **预防系统发生死锁**

见：<https://javaguide.cn/cs-basics/operating-system/operating-system-basic-questions-01.html#%E8%A7%A3%E5%86%B3%E6%AD%BB%E9%94%81%E7%9A%84%E6%96%B9%E6%B3%95>

第二种方法换成顺序资源分配法

**顺序资源分配法**：首先给系统中的资源编号，规定每个进程必须按编号递增的顺序请求资源，同类资源一次申请完。也就是说，只要进程提出申请分配资源R;，则该进程在以后的资源申请中就只能申请编号大于 R的资源。

#### 死锁如何避免？

死锁的预防会导致 **低效的进程运行** 和 **资源使用率** 。而死锁的避免相反，它的角度是允许系统中**同时存在四个必要条件** ，只要掌握并发进程中与每个进程有关的资源动态申请情况，做出 **明智和合理的选择** ，仍然可以避免死锁，因为四大条件仅仅是产生死锁的必要条件。

见：<https://javaguide.cn/cs-basics/operating-system/operating-system-basic-questions-01.html#%E8%A7%A3%E5%86%B3%E6%AD%BB%E9%94%81%E7%9A%84%E6%96%B9%E6%B3%95>

<http://www.cyc2018.xyz/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E6%AD%BB%E9%94%81.html#%E6%AD%BB%E9%94%81%E9%81%BF%E5%85%8D>

#### 死锁如何检测？

对资源的分配加以限制可以 **预防和避免** 死锁的发生，但是都不利于各进程对系统资源的**充分共享**。解决死锁问题的另一条途径是 **死锁检测和解除**。这种方法对资源的分配不加以任何限制，也不采取死锁避免措施，但系统 **定时地运行一个 “死锁检测”** 的程序，判断系统内是否出现死锁，如果检测到系统发生了死锁，再采取措施去解除它。

具体操作见王道操作系统

#### 死锁如何解除？

当死锁检测程序检测到存在死锁发生时，应设法让其解除，让系统从死锁状态中恢复过来，常用的解除死锁的方法有以下四种：

1. **立即结束所有进程的执行，重新启动操作系统** ：这种方法简单，但以前所在的工作全部作废，损失很大。
2. **撤销涉及死锁的所有进程，解除死锁后继续运行** ：这种方法能彻底打破**死锁的循环等待**条件，但将付出很大代价，例如有些进程可能已经计算了很长时间，由于被撤销而使产生的部分结果也被消除了，再重新执行时还要再次进行计算。
3. **逐个撤销涉及死锁的进程，回收其资源直至死锁解除。**
4. **抢占资源** ：从涉及死锁的一个或几个进程中抢占资源，把夺得的资源再分配给涉及死锁的进程直至死锁解除。

## 操作系统内存管理基础

### 操作系统的内存管理主要是做什么？

1. 内存的分配与回收
2. 逻辑地址映射为物理地址

### 操作系统的内存管理机制了解吗？内存管理有哪几种方式？

可以分为连续分配管理方式和非连续分配管理方式：

- 连续分配管理方式就是为一个用户程序分配一个连续的内存空间，比如块式管理
- 非连续分配管理方式就是为一个用户程序分配内存空间不一定是连续的，比如页式管理，段式管理，段页式管理

见：<https://javaguide.cn/cs-basics/operating-system/operating-system-basic-questions-01.html#%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E4%BB%8B%E7%BB%8D>

注意看下流程

### 快表和多级页表是什么？

见：<https://javaguide.cn/cs-basics/operating-system/operating-system-basic-questions-01.html#%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E4%BB%8B%E7%BB%8D>

注意看下流程

### 分页机制和分段机制有哪些共同点和区别呢？

1. 共同点
   - 分页机制和分段机制都是为了提高内存利用率，减少内存碎片。
   - 页和段都是离散存储的，所以两者都是离散分配内存的方式。但是，每个页和段中的内存是连续的。
2. 区别
   - 页的大小是固定的，由操作系统决定；而段的大小不固定，取决于我们当前运行的程序。
   - 分页仅仅是为了满足操作系统内存管理的需求，而段是逻辑信息的单位，在程序中可以体现为代码段，数据段，能够更好满足用户的需要。

### 逻辑地址和物理地址是什么？

我们编程一般只有可能和逻辑地址打交道，比如在 C 语言中，指针里面存储的数值就可以理解成为内存里的一个地址，这个地址也就是我们说的逻辑地址，逻辑地址由操作系统决定。物理地址指的是真实物理内存中地址，更具体一点来说就是内存地址寄存器中的地址。物理地址是内存单元真正的地址。

### CPU 寻址是什么？为什么需要虚拟地址空间？

#### 为什么要有虚拟地址空间呢？

都见：<https://javaguide.cn/cs-basics/operating-system/operating-system-basic-questions-01.html#%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E4%BB%8B%E7%BB%8D>

和其他书籍，这个说的不是很好，可以看一下所有流程

### 什么是虚拟内存？

这个在我们平时使用电脑特别是 Windows 系统的时候太常见了。很多时候我们使用了很多占内存的软件，这些软件占用的内存可能已经远远超出了我们电脑本身具有的物理内存。**为什么可以这样呢？** 正是因为 **虚拟内存** 的存在，通过 **虚拟内存** 可以让程序拥有超过系统物理内存大小的可用内存空间。另外，**虚拟内存为每个进程提供了一个一致的、私有的地址空间，它让每个进程产生了一种自己在独享主存的错觉（每个进程拥有一片连续完整的内存空间）**。这样会更加有效地管理内存并减少出错。

**虚拟内存**是计算机系统内存管理的一种技术，我们可以手动设置自己电脑的虚拟内存。不要单纯认为虚拟内存只是“使用硬盘空间来扩展内存“的技术。**虚拟内存的重要意义是它定义了一个连续的虚拟地址空间**，并且 **把内存扩展到硬盘空间**。

### 局部性原理是什么？

局部性原理表现在以下两个方面：

1. **时间局部性** ：如果程序中的某条指令一旦执行，不久以后该指令可能再次执行；如果某数据被访问过，不久以后该数据可能再次被访问。产生时间局部性的典型原因，是由于在程序中存在着大量的循环操作。
2. **空间局部性** ：一旦程序访问了某个存储单元，在不久之后，其附近的存储单元也将被访问，即程序在一段时间内所访问的地址，可能集中在一定的范围之内，这是因为指令通常是顺序存放、顺序执行的，数据也一般是以向量、数组、表等形式簇聚存储的。

### 虚拟内存技术是怎么实现的？

见：<https://javaguide.cn/cs-basics/operating-system/operating-system-basic-questions-01.html#%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E4%BB%8B%E7%BB%8D>

### 页面置换算法的作用？常见的页面置换算法有哪些？

缺页中断时，如果当前内存已经满了就需要选择页移除内存，那么移除哪个页就是页面置换算法，有FIFO，LRU，LFU

见：<https://javaguide.cn/cs-basics/operating-system/operating-system-basic-questions-01.html#%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E4%BB%8B%E7%BB%8D>

# MySQL

## 基础

### drop、delete 与 truncate 区别？

drop会把表删掉，delete和truncate不会

delete删除的时候有回滚日志，truncate没有

## MySQL 基础架构

![img](https://guide-blog-images.oss-cn-shenzhen.aliyuncs.com/javaguide/13526879-3037b144ed09eb88.png)

- **连接器：** 身份认证和权限相关(登录 MySQL 的时候)。

- **查询缓存：** 执行查询语句的时候，会先查询缓存（MySQL 8.0 版本后移除，因为这个功能不太实用）。

- **分析器：** 没有命中缓存的话，SQL 语句就会经过分析器，分析器说白了就是要先看你的 SQL 语句要干嘛，再检查你的 SQL 语句语法是否正确。

- **优化器：** 按照 MySQL 认为最优的方案去执行。

- **执行器：** 执行语句，然后从存储引擎返回数据。

简单来说 MySQL 主要分为 Server 层和存储引擎层：

- **Server 层**：主要包括连接器、查询缓存、分析器、优化器、执行器等，所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图，函数等，还有一个通用的日志模块 binlog 日志模块。
- **存储引擎**： 主要负责数据的存储和读取，采用可以替换的插件式架构，支持 InnoDB、MyISAM、Memory 等多个存储引擎，其中 InnoDB 引擎有自有的日志模块 redolog 模块。**现在最常用的存储引擎是 InnoDB，它从 MySQL 5.5 版本开始就被当做默认存储引擎了。**

**总结：**

- MySQL 主要分为 Server 层和引擎层，Server 层主要包括连接器、查询缓存、分析器、优化器、执行器，同时还有一个日志模块（binlog），这个日志模块所有执行引擎都可以共用，redolog 只有 InnoDB 有。

- 引擎层是插件式的，目前主要包括，MyISAM,InnoDB,Memory 等。

详见：<https://javaguide.cn/database/mysql/how-sql-executed-in-mysql.html#_1-2-server-%E5%B1%82%E5%9F%BA%E6%9C%AC%E7%BB%84%E4%BB%B6%E4%BB%8B%E7%BB%8D>

### 一个 SQL 语句在 MySQL 中的执行流程

- 查询语句的执行流程如下：连接器权限校验（如果命中缓存）--->查询缓存--->分析器--->优化器--->权限校验--->执行器--->引擎

- 更新语句执行流程如下：连接器权限校验---->分析器---->权限校验---->执行器--->引擎---redo log(prepare 状态)--->binlog--->redo log(commit状态)

详见：<https://javaguide.cn/database/mysql/how-sql-executed-in-mysql.html#_1-2-server-%E5%B1%82%E5%9F%BA%E6%9C%AC%E7%BB%84%E4%BB%B6%E4%BB%8B%E7%BB%8D>

## MySQL存储引擎

### MyISAM 和 InnoDB 有什么区别？

1. MyISAM 不支持行级锁、事务、外键、MVCC，而 InnoDB 支持。
2. MyISAM 的索引数据与key是分开的，InnoDB是在一起的
3. MyISAM 不支持数据库异常崩溃后的安全恢复（redolog），而 InnoDB 支持。
4. InnoDB 的性能比 MyISAM 更强大。

### MyISAM 和 InnoDB 如何选择？

大多数时候我们使用的都是 InnoDB 存储引擎，在某些读密集的情况下，使用 MyISAM 也是合适的

## MySQL日志

日志分为redo log、undo log、bin log

### redo log

redo log（重做日志）是InnoDB存储引擎独有的，它让MySQL拥有了崩溃恢复能力（即crash-safe）。

#### 刷盘时机

redo log有三种模式

- 0，事务提交时，不写盘
- 1，事务提交时，写盘
- 2，事务提交时，将数据写到操作系统的page cache里，等待操作系统的fsync

注意page cache之上还有一个redo log buffer，用来存储需要写盘的redo log

除了事务提交时写盘，redo log还有一个后台线程每隔1 秒，就会把 redo log buffer 中的内容写到文件系统缓存（page cache），然后调用 fsync 刷盘。

#### 日志文件组

日志文件共4个，循环在一起，如下图所示：

![img](https://guide-blog-images.oss-cn-shenzhen.aliyuncs.com/github/javaguide/11.png)

有两个指针，write pos表示目前redo log写到哪了，checkpoint表示目前把redo log里的东西哪些写到数据库了

#### 有功夫刷redo log，为什么不直接刷数据？

因为redo log是连续访问并且数据量小，刷写速度快，直接刷数据，是随机访问并且数据量大，刷写速度慢

### binlog

`redo log` 它是物理日志，记录内容是“在某个数据页上做了什么修改”，属于 `InnoDB` 存储引擎。

而 `binlog` 是逻辑日志，记录内容是语句的原始逻辑，类似于“给 ID=2 这一行的 c 字段加 1”，属于`MySQL Server` 层。

不管用什么存储引擎，只要发生了表数据更新，都会产生 `binlog` 日志。

那 `binlog` 到底是用来干嘛的？

可以说`MySQL`数据库的**数据备份、主备、主主、主从**都离不开`binlog`，需要依靠`binlog`来同步数据，保证数据一致性。

#### 记录格式

binlog记录格式有三种

- **statement**，sql语句原文
- **row**，会将now()等函数换成具体的时间
- **mixed**，上述两个东西的混合

#### 写入机制

`binlog`的写入时机也非常简单，事务执行过程中，先把日志写到`binlog cache`，事务提交的时候，再把`binlog cache`写到`binlog`文件中。

### 两阶段提交

`redo log`（重做日志）让`InnoDB`存储引擎拥有了崩溃恢复能力。

`binlog`（归档日志）保证了`MySQL`集群架构的数据一致性。

两者的写时机不一样，redo log是事务执行的同时就会写，binlog事务执行完毕才会写，那么有可能出现不一致的情况，为了解决这个问题提出了两阶段提交方案

原理很简单，将`redo log`的写入拆成了两个步骤`prepare`和`commit`，这就是**两阶段提交**，如下所示

![img](https://guide-blog-images.oss-cn-shenzhen.aliyuncs.com/github/javaguide/04-20220305234956774.png)

### undo log

就是记录之前的版本的集合，用链表的结构串起来，也是MVCC的基础之一

有很多考点

详见：<https://javaguide.cn/database/mysql/mysql-logs.html>

### 为什么需要undo log

1. **实现事务回滚，保障事务的原子性**
2. **实现 MVCC（多版本并发控制）关键因素之一**。MVCC 是通过 ReadView + undo log 实现的。undo log 为每条记录保存多份历史数据

### 为什么需要redo log

1. **实现事务的持久性，让 MySQL 有 crash-safe 的能力**，能够保证 MySQL 在任何时间段突然崩溃，重启后之前已提交的记录都不会丢失；
2. **将写操作从「随机写」变成了「顺序写」**，提升 MySQL 写入磁盘的性能。因为写数据时先写redo log，以后有时间再写入数据库

### redo log 和 undo log 区别

1. redo log 记录了此次事务「**完成后**」的数据状态，记录的是更新**之后**的值；
2. undo log 记录了此次事务「**开始前**」的数据状态，记录的是更新**之前**的值；

### redo log 要写到磁盘，数据也要写磁盘，为什么要多此一举？

因为redo log是连续访问并且数据量小，刷写速度快，直接刷数据，是随机访问并且数据量大，刷写速度慢

### redo log 什么时候刷盘

刷盘策略有一个参数：

**0** ：设置为 0 的时候，表示每次事务提交时不进行刷盘操作，只写到redo log buffer

**1** ：设置为 1 的时候，表示每次事务提交时都将进行刷盘操作（默认值）

**2** ：设置为 2 的时候，表示每次事务提交时都只把 redo log buffer 内容写入 page cache

除此之外，`InnoDB` 存储引擎有一个后台线程，每隔`1` 秒，就会把 `redo log buffer` 中的内容写到文件系统缓存（`page cache`），然后调用 `fsync` 刷盘。

### redo log 文件写满了怎么办

因为redo log的日志文件组是循环写，如果 write pos 追上了 checkpoint，就意味着 redo log 文件满了，这时 MySQL 不能再执行新的更新操作，也就是说 MySQL 会被阻塞

### 为什么需要 binlog

因为需要做数据备份或者主从复制

### redo log 和 binlog 有什么区别

1. **层级不同：**redo log处于引擎层，binlog处于server层
2. **文件格式不同：**binlog 有 3 种格式类型，分别是 STATEMENT（默认格式）、ROW、 MIXED，redo log 是物理日志，记录的是在某个数据页做了什么修改
3. **写入方式不同：**binlog 是追加写，写满一个文件，就创建一个新的文件继续写，redo log 是循环写
4. **用途不同：**binlog 用于备份恢复、主从复制，redo log 用于掉电等故障恢复。

### 能使用 redo log 文件恢复数据吗

不能，因为redo log是会覆盖的

### binlog 什么时候刷盘

1. sync_binlog = 0 的时候，表示每次提交事务都只 write，不 fsync，后续交由操作系统决定何时将数据持久化到磁盘；
2. sync_binlog = 1 的时候，表示每次提交事务都会 write，然后马上执行 fsync；
3. sync_binlog =N(N>1) 的时候，表示每次提交事务都 write，但累积 N 个事务后才 fsync。

### update 语句的执行过程

具体更新一条记录 `UPDATE t_user SET name = 'xiaolin' WHERE id = 1;` 的流程如下:

1. 执行器负责具体执行，会调用存储引擎的接口，通过主键索引树搜索获取 id = 1 这一行记录：
   - 如果 id=1 这一行所在的数据页本来就在 buffer pool 中，就直接返回给执行器更新；
   - 如果记录不在 buffer pool，将数据页从磁盘读入到 buffer pool，返回记录给执行器。
2. 执行器得到聚簇索引记录后，会看一下更新前的记录和更新后的记录是否一样：
   - 如果一样的话就不进行后续更新流程；
   - 如果不一样的话就把更新前的记录和更新后的记录都当作参数传给 InnoDB 层，让 InnoDB 真正的执行更新记录的操作；
3. 开启事务， InnoDB 层更新记录前，首先要记录相应的 undo log，因为这是更新操作，需要把被更新的列的旧值记下来，也就是要生成一条 undo log，undo log 会写入 Buffer Pool 中的 Undo 页面，不过在内存修改该 Undo 页面后，需要记录对应的 redo log。
4. InnoDB 层开始更新记录，会先更新内存（同时标记为脏页），然后将记录写到 redo log 里面，这个时候更新就算完成了。为了减少磁盘I/O，不会立即将脏页写入磁盘，后续由后台线程选择一个合适的时机将脏页写入到磁盘。这就是 **WAL 技术**，MySQL 的写操作并不是立刻写到磁盘上，而是先写 redo 日志，然后在合适的时间再将修改的行数据写到磁盘上。
5. 至此，一条记录更新完了。
6. 在一条更新语句执行完成后，然后开始记录该语句对应的 binlog，此时记录的 binlog 会被保存到 binlog cache，并没有刷新到硬盘上的 binlog 文件，在事务提交时才会统一将该事务运行过程中的所有 binlog 刷新到硬盘。
7. 事务提交（为了方便说明，这里不说组提交的过程，只说两阶段提交）：
   - **prepare 阶段**：将 redo log 对应的事务状态设置为 prepare，然后将 redo log 刷新到硬盘；
   - **commit 阶段**：将 binlog 刷新到磁盘，接着调用引擎的提交事务接口，将 redo log 状态设置为 commit（将事务设置为 commit 状态后，刷入到磁盘 redo log 文件）；
8. 至此，一条更新语句执行完成。

### 为什么需要两阶段提交

因为redo log 和 binlog的写盘的独立的，有可能出现一个写入了，一个没写入的情况，redo log 影响主库的数据，binlog 影响从库的数据，所以 redo log 和 binlog 必须保持一致才能保证主从数据一致。MySQL 为了避免出现两份日志之间的逻辑不一致的问题，使用了「两阶段提交」来解决，两阶段提交把单个事务的提交拆分成了 2 个阶段，分别是「准备（Prepare）阶段」和「提交（Commit）阶段」

### 两阶段提交的过程是怎样的

![img](https://guide-blog-images.oss-cn-shenzhen.aliyuncs.com/github/javaguide/04-20220305234956774.png)

### 两阶段提交中异常重启会出现什么现象

记住异常重启之后以binlog的为准

## MySQL 索引

### 索引是什么

索引是一种用于快速查询和检索数据的数据结构，其本质可以看成是一种排序好的数据结构。索引的作用就相当于书的目录。MySQL一般使用B+树

### 理解

就是B+树，用来加速查找过程的，主键会自动建一个索引，也可以手动建索引，但是非主键索引是非聚簇索引，需要回表再查一次主键索引，为了避免回表，产生了覆盖索引，覆盖索引就是索引里的key包含了要查询的字段，联合索引符合最左前缀匹配原则

MyISAM的索引都是非聚簇索引，但是叶子节点的存的不是主键而是数据的指针，而InnoDB的非聚簇索引存的主键

### 索引的分类

- 按「数据结构」分类：**B+tree索引、Hash索引、Full-text索引**。
- 按「物理存储」分类：**聚簇索引（主键索引）、二级索引（辅助索引）**。
- 按「字段特性」分类：**主键索引、唯一索引、普通索引、前缀索引**。
- 按「字段个数」分类：**单列索引、联合索引**。

### 聚簇索引可以是哪些列生成

- 如果有主键，默认会使用主键作为聚簇索引的索引键（key）
- 如果没有主键，就选择第一个不包含 NULL 值的唯一列作为聚簇索引的索引键（key）
- 在上面两个都没有的情况下，InnoDB 将自动生成一个隐式自增 id 列作为聚簇索引的索引键（key）

### B+树 vs B树

- B+Tree 只在叶子节点存储数据，而 B 树 的非叶子节点也要存储数据
- B+Tree 叶子节点采用的是双链表连接，适合 MySQL 中常见的基于范围的顺序查找，而 B 树无法做到这一点

### B+树 vs 二叉树

B+树由于一个结点里存的数据多，所以比二叉树矮，所以磁盘IO次数少

### B+树 vs Hash索引

Hash 在做等值查询的时候效率贼快，搜索复杂度为 O(1)。

但是 Hash 表不适合做范围查询，它更适合做等值的查询

### 联合索引的最左匹配原则

如果不满足最左匹配原则的话，索引会失效，因为除了最左边的索引，其他索引都不是全局有序的，需要注意的是where后面条件因为有优化器的存在，即使最左边的字段没有放在最左边也会优化到最左边

联合索引的最左匹配原则，在遇到范围查询（如 >、<）的时候，就会停止匹配，也就是范围查询的字段可以用到联合索引，但是在范围查询字段的后面的字段无法用到联合索引。注意，对于 >=、<=、BETWEEN、like 前缀匹配的范围查询，并不会停止匹配

### 索引下推优化

可以在联合索引遍历过程中，对联合索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数

### 索引的缺点

1. 占用物理空间
2. 维护和创建索引需要时间，会降低增删改的性能

### 什么时候适用索引

1. 字段有唯一性限制的
2. 经常用于 `WHERE` 查询条件的字段
3. 经常用于 `GROUP BY` 和 `ORDER BY` 的字段，这样在查询的时候就不需要再去做一次排序了

### 什么时候不适用索引

1. `WHERE` 条件，`GROUP BY`，`ORDER BY` 里用不到的字段
2. 字段中存在大量重复数据，不需要创建索引，比如性别字段
3. 表数据太少的时候，不需要创建索引；
4. 经常更新的字段不用创建索引，因为维护索引是会影响数据库性能的。

### 优化索引的方法

1. 前缀索引优化
2. 覆盖索引优化
3. 主键索引最好是自增的
4. 防止索引失效

### 索引失效的几种情况

1. 当我们使用左或者左右模糊匹配的时候，也就是 `like %xx` 或者 `like %xx%`这两种方式都会造成索引失效；
2. 当我们在查询条件中对索引列使用函数，就会导致索引失效。
3. 当我们在查询条件中对索引列进行表达式计算，也是无法走索引的。
4. MySQL 在遇到字符串和数字比较的时候，会自动把字符串转为数字，然后再进行比较。如果字符串是索引列，而条件语句中的输入参数是数字的话，那么索引列会发生隐式类型转换，由于隐式类型转换是通过 CAST 函数实现的，等同于对索引列使用了函数，所以就会导致索引失效。
5. 联合索引要能正确使用需要遵循最左匹配原则，也就是按照最左优先的方式进行索引的匹配，否则就会导致索引失效。
6. 在 WHERE 子句中，如果在 OR 前的条件列是索引列，而在 OR 后的条件列不是索引列，那么索引会失效。

### 索引设计



## MySQL事务

事务就是为了处理并发请求时保持数据一致性提出的解决方案，一般用ACID性质来判断事务隔离的等级

并发事务会带来脏读、丢失修改、不可重复读、幻读等问题

为了解决这些问题，提出了4个事务隔离级别，分别解决一个问题（实际上mysql的可重复读级别能解决幻读问题），事务隔离是通过锁和MVCC来实现的

有很多考点

详见：<https://javaguide.cn/database/mysql/mysql-questions-01.html#mysql-%E4%BA%8B%E5%8A%A1>

### 事务有哪些特性？

- **原子性（Atomicity）**：一个事务中的所有操作，要么全部完成，要么全部不完成
- **一致性（Consistency）**：是指事务操作前和操作后，数据满足完整性约束，数据库保持一致性状态
- **隔离性（Isolation）**：隔离性可以防止并发事务由于交叉执行而导致数据的不一致
- **持久性（Durability）**：事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。

### InnoDB如何保证四个特性

- 持久性是通过 redo log （重做日志）来保证的；
- 原子性是通过 undo log（回滚日志） 来保证的；
- 隔离性是通过 MVCC（多版本并发控制） 或锁机制来保证的；
- 一致性则是通过持久性+原子性+隔离性来保证；

### 并行事务会引发什么问题

MySQL 服务端是允许多个客户端连接的，这意味着 MySQL 会出现同时处理多个事务的情况。

那么**在同时处理多个事务的时候，就可能出现脏读（dirty read）、不可重复读（non-repeatable read）、幻读（phantom read）的问题**。

### MySQL事务隔离级别

为了解决事务并发带来的问题，提出了4个事务隔离级别：

- **读未提交（read uncommitted）**，指一个事务还没提交时，它做的变更就能被其他事务看到；
- **读提交（read committed）**，指一个事务提交之后，它做的变更才能被其他事务看到，可以解决脏读问题
- **可重复读（repeatable read）**，指一个事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，**MySQL InnoDB 引擎的默认隔离级别**，可以解决不可重复读问题
- **串行化（serializable ）**；会对记录加上读写锁，在多个事务对这条记录进行读写操作时，如果发生了读写冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行，可以解决幻读问题

mysql的RR级别能在一定程度上解决幻读问题，快照读用MVCC解决，当前读用临键锁来解决

注意真正解决幻读问题必须用锁，因为快照读的情况下可以使用MVCC解决，当前读的情况下必须加临键锁解决

- 快照读（一致性非锁定读），使用MVCC机制，读取快照
- 当前读（一致性锁定读），使用锁机制，加S锁或者X锁，读取最新数据

有很多考点

详见：<https://javaguide.cn/database/mysql/transaction-isolation-level.html>

### MVCC

MVCC即多版本并发控制，就是事务并发的时候保留记录的多个版本，以实现事务的各个隔离等级

数据库并发的时候有三种情况，读读，读写，写写，读读不用管，写写加乐观锁或者悲观锁即可，那么读写呢？

读写最开始是用加锁的方式解决的，但是加锁效率太低，所以进入了MVCC来解决读写问题，使读写的时候不需要阻塞

MVCC依赖于记录的隐藏字段、undolog、readview来实现的：

- 隐藏字段：包括隐含的自增ID、最近修改(修改/插入)事务ID、回滚指针、删除flag
- undolog：就是记录的多个版本组成的链表
- readview：就是一个结构体，里面包含未提交的事务id、未提交事务id的最小的id、readview生成时最大的事务id+1

#### MVCC是怎么实现快照功能的

所以MVCC的流程就是第一次读取的时候生成一个readview，然后以后每次读取的时候都走这个生成的readview，具体流程就是，看读取记录隐藏字段的最后修改事务id是否大于readview生成时的最大事务id，或者最后修改事务id在生成readview时没有提交，这两种情况需要从undolog里找，否则直接读即可

根据这个流程，每次读取都必定读取到第一次读取时的结果，所以可以把readview看成一个快照，所以这时候的读称为快照读

基于MVCC就可以解决不可重复读和在一定程度上解决幻读问题，实现RR（可重复读）隔离等级

注意RC隔离级别也会使用MVCC，但是和RR级别生成readview的时机不一样，RC级别每次都都会生成readview，RR级别只有第一次读会生成

有很多考点

详见：<https://pdai.tech/md/db/sql-mysql/sql-mysql-mvcc.html>

### 数据库事务并发控制

在数据库系统领域，并发控制机制主要有两种，即锁和多版本机制。

**1.事务在加锁时有多种方式：**

**一次性锁协议**，事务开始时，即一次性申请所有的锁，之后不会再申请任何锁，如果其中某个锁不可用，则整个申请就不成功，事务就不会执行，在事务尾端，一次性释放所有的锁。一次性锁协议不会产生死锁的问题，但事务的并发度不高。

**两阶段锁协议**，整个事务分为两个阶段，前一个阶段为加锁，后一个阶段为解锁。在加锁阶段，事务只能加锁，也可以操作数据，但不能解锁，直到事务释放第一个锁，就进入解锁阶段，此过程中事务只能解锁，也可以操作数据，不能再加锁。两阶段锁协议使得事务具有较高的并发度，因为解锁不必发生在事务结尾。它的不足是没有解决死锁的问题，因为它在加锁阶段没有顺序要求。如两个事务分别申请了A, B锁，接着又申请对方的锁，此时进入死锁状态。

**2.多版本机制**：

锁是针对集中式数据管理设计的，缺点是降低了事务的并发，并且锁本身有开销。在分布式系统，尤其是读多写少的系统中，采用多版本机制更合适。每个数据项都有多个副本，每个副本都有一个时间戳，根据多版本并发控制协议(MVCC)维护各个版本。

## MySQL锁

有几种锁呢？

1. 按照锁的粒度划分：行锁、表锁
2. 按照锁的使用方式划分：共享锁、排它锁(悲观锁的一种实现)
3. 还有两种思想上的锁：悲观锁、乐观锁。
4. InnoDB中有几种行级锁类型：Record Lock、Gap Lock、Next-key Lock
5. 一种特殊的锁，意向锁

### 行锁和表锁

一个锁行一个锁表，注意行级锁是锁索引的，所以如果加锁查询中where条件中字段索引失效的话就会全表扫描，导致全表上锁，然后过滤之后再解锁，而且如果查询字段是一个非聚簇索引，那么就会对该非聚簇索引和聚簇索引相应的记录都加锁，而且如果字段命中的是普通索引，会使用临键锁类型的行锁，因为普通索引会有相同的key，为了保证查询范围内的记录都不能更改（为了防止幻读），所以都得加锁，所以会使用临键锁类型的行锁

### 共享锁和排他锁

排他锁与任何的锁都不兼容，共享锁仅和共享锁兼容。

### 悲观锁和乐观锁

是思想上的东西，mysql里没有具体的实现，乐观锁读取时不加锁，写入时判断版本时候已经更新，悲观锁读取时即加锁

### Record Lock和Gap Lock和Next-key Lock

Record Lock只对记录加锁，Gap Lock对间隙加锁，Next-key Lock对记录和间隙加锁，主要是为了解决幻读问题的

至于到底加什么样的锁，主要看加什么样的锁能保证不会出现幻读问题，比如查询条件是唯一索引的列==一个具体的值，那么只需要对这条记录加锁（其实是对索引加锁）就可以了，但是如果是普通索引或者范围查找的话，就需要加临键锁了

### 意向锁

如果需要用到表锁的话，如何判断表中的记录没有行锁呢，一行一行遍历肯定是不行，性能太差。我们需要用到一个叫做意向锁的东东来快速判断是否可以对某个表使用表锁。

意向锁是表级锁，共有两种：

- **意向共享锁（Intention Shared Lock，IS 锁）**：事务有意向对表中的某些记录加共享锁（S 锁），加共享锁前必须先取得该表的 IS 锁。
- **意向排他锁（Intention Exclusive Lock，IX 锁）**：事务有意向对表中的某些记录加排他锁（X 锁），加排他锁之前必须先取得该表的 IX 锁。

**意向锁是有数据引擎自己维护的，用户无法手动操作意向锁，在为数据行加共享/排他锁之前，InooDB 会先获取该数据行所在在数据表的对应意向锁。**

意向锁之间是互相兼容的。

|       | IS 锁 | IX 锁 |
| ----- | ----- | ----- |
| IS 锁 | 兼容  | 兼容  |
| IX 锁 | 兼容  | 兼容  |

意向锁和共享锁和排它锁互斥（这里指的是表级别的共享锁和排他锁，意向锁不会与行级的共享锁和排他锁互斥）。

|      | IS 锁 | IX 锁 |
| ---- | ----- | ----- |
| S 锁 | 兼容  | 互斥  |
| X 锁 | 互斥  | 互斥  |

有很多考点

详见：<https://javaguide.cn/database/mysql/mysql-questions-01.html#mysql-%E9%94%81>

<https://ost.51cto.com/posts/11812>

## MySQL优化

### 读写分离

<https://javaguide.cn/high-performance/read-and-write-separation-and-library-subtable.html#%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB>

### 分库分表

<https://javaguide.cn/high-performance/read-and-write-separation-and-library-subtable.html#%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8>

### MySQL执行计划

<https://javaguide.cn/database/mysql/mysql-query-execution-plan.html>

## MySQL整体流程

mysql默认隔离等级是RR，需要解决不可重复读和幻读的问题，如果是普通的select，那么由于MVCC机制就可以解决这个问题，这种读就是快照读，如果是带锁的select，就是当前读，带锁的select可以解决不可重复读的问题，但是不能解决幻读的问题，为了解决幻读问题，需要用到临键锁（记录锁+间隙锁），而且如果where条件没有命中索引的话，需要全表扫描，也就会全表加锁，如果where条件没有命中唯一索引或者查询的是个范围的话，会加临键锁，如果where条件命中唯一索引且只查找具体的记录的话，只加记录锁（更一般的说，只要是需要加锁的操作，都是这个模式）

# Redis

直接看小林coding吧

## 数据结构

### Redis 数据类型以及使用场景分别是什么？

Redis有5种数据类型：String（字符串），Hash（哈希），List（列表），Set（集合）、Zset（有序集合）。

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/redis/%E5%85%AB%E8%82%A1%E6%96%87/key.png)

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/redis/%E5%85%AB%E8%82%A1%E6%96%87/%E4%BA%94%E7%A7%8D%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B.png)

Redis 五种数据类型的应用场景：

- String 类型的应用场景：缓存对象、常规计数、分布式锁、共享 session 信息等。
- List 类型的应用场景：消息队列（但是有两个问题：1. 生产者需要自行实现全局唯一 ID；2. 不能以消费组形式消费数据）等。
- Hash 类型：缓存对象、购物车等。
- Set 类型：聚合计算（并集、交集、差集）场景，比如点赞、共同关注、抽奖活动等。
- Zset 类型：排序场景，比如排行榜、电话和姓名排序等。

### 五种常见的 Redis 数据类型是怎么实现？

![img](https://img-blog.csdnimg.cn/img_convert/9fa26a74965efbf0f56b707a03bb9b7f.png)

#### String 类型

底层使用SDS数据结构，相当于封装好的字符串类型

#### List 类型

底层使用压缩列表或者双向链表，数据量小的时候使用压缩列表，不过新版本已经全部换成quicklist了

#### Hash 类型

底层使用压缩列表或者哈希表，数据量小的时候使用压缩列表，不过新版本压缩列表已经废弃了，换成listpack了

#### Set 类型

底层使用哈希表或者整数集合，如果数据都是整数并且数据量较小的话就用整数集合，否则用哈希表

#### ZSet 类型

底层使用压缩列表或者跳表，数据量小的时候使用压缩列表，不过新版本压缩列表已经废弃了，换成listpack了

### 数据结构

#### SDS

![img](https://img-blog.csdnimg.cn/img_convert/516738c4058cdf9109e40a7812ef4239.png)

看图

#### 压缩列表

![img](https://img-blog.csdnimg.cn/img_convert/a3b1f6235cf0587115b21312fe60289c.png)

zlbytes：占用的字节数

zltail：尾结点的偏移量

zllen：结点的个数

zlend：结束的标识符，0xFF

prevlen：前一个结点的长度，为了实现从后向前遍历

encoding：当前结点的类型和长度

data：当前结点的真实数据

会发生连锁反应，因为压缩列表在内存中是连续的，一个结点如果修改了之后变大了，那么后一个结点的prevlen就有可能从1字节变成5字节，这样就会导致后面节点变大了，后面节点变大了又会导致后面后面的结点变大了，以此类推

#### 双向链表

![img](https://img-blog.csdnimg.cn/img_convert/cadf797496816eb343a19c2451437f1e.png)

就是很正常的双向链表，看图

#### 哈希表

![img](https://img-blog.csdnimg.cn/img_convert/2fedbc9cd4cb7236c302d695686dd478.png)

跟Java的map一样都是链地址法，dict里的两个ht是用来rehash的，为什么要rehash？因为随着数据量的增加，哈希桶不变的情况下，hash碰撞会越来越多，链表也越来越长，所以要适当增加哈希桶，那么就需要rehash，先在ht[1]里rehash，然后交换ht[0]和ht[1]，但是rehash阻塞太久了，所以可以采用渐进式rehash，就是redis增删改查的时候顺便给操作的元素rehash了，只要时间足够久，就能把元素全部rehash到另一个表上

### 整数集合

![img](https://img-blog.csdnimg.cn/img_convert/e2e3e19fc934e70563fbdfde2af39a2b.png)

整数集合就是整数数组，有时候整数数组的元素类型是int，但是传进来一个long，那么就需要升级，升级的操作就是先开辟一个2倍空间的数组，然后将原元素均匀的分布在新数组上

### 跳表

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/redis/%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/3%E5%B1%82%E8%B7%B3%E8%A1%A8-%E8%B7%A8%E5%BA%A6.drawio.png)

普通链表查询只能从左往右找一遍，但是跳表是有顺序的，可以直接从最高层找，这样就可以加快查找速度

为什么用跳表而不用平衡树？范围查找方便、内存占用少、算法实现简单

### quicklist

![img](https://img-blog.csdnimg.cn/img_convert/f46cbe347f65ded522f1cc3fd8dba549.png)

融合了双向链表和压缩列表

## 线程模型

redis是单线程IO多路复用

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/redis/%E5%85%AB%E8%82%A1%E6%96%87/redis%E5%8D%95%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B.drawio.png)

### Redis 采用单线程为什么还这么快？

- Redis 的大部分操作**都在内存中完成**，并且采用了高效的数据结构
- Redis 采用单线程模型可以**避免了多线程之间的竞争**
- Redis 采用了 **I/O 多路复用机制**处理大量的客户端 Socket 请求

## 持久化

为了实现数据不丢失，所以redis需要持久化

### AOF

就是把命令存到AOF文件里

流程：

![img](https://img-blog.csdnimg.cn/img_convert/4eeef4dd1bedd2ffe0b84d4eaa0dbdea.png)

三种写回策略：

![img](https://img-blog.csdnimg.cn/img_convert/98987d9417b2bab43087f45fc959d32a.png)

如果AOF过大就会重写，重写的原理就是读取内存的数据，然后写到新的AOF文件里，但是这样会阻塞很久，所以有了后台重写的方案，就是开一个子进程，子进程和父进程的页表一样，所以指向同一块内存，由于写时复制技术，当一个进程修改内存时，会把该内存复制一份，所以就好像两个进程各自有一块内存，那么子进程就可以读取此时的内存并写入AOF文件中，但是注意这时候的子进程的内存是个快照，在写入AOF文件的时候，主进程依然在接受命令，所以将这些命令存到AOF重写缓冲区中，等子进程重写完AOF就把这个缓冲区的命令加到AOF文件里面，这样就保证了新AOF文件和内存数据的一致性

#### AOF 日志过大，会触发什么机制？

会触发重写机制，会把内存里的数据用命令表示一遍，然后把这些命令写入AOF文件

#### AOF重写流程

1. 主进程就会创建重写 AOF 的子进程
2. 重写 AOF 子进程会读取数据库里的所有数据，并逐一把内存数据的键值对转换成一条命令，再将命令记录到新的 AOF 文件
3. 重写过程中，主进程依然可以正常处理命令，如果主进程修改数据会发生写时复制技术，并且会出现内存数据与新AOF文件数据不一致的情况，所以需要**AOF 重写缓冲区**，这个缓冲区在存储从开始重写的写命令，当子进程完成 AOF 重写工作后再把这个缓冲区的内容写到AOF文件后面
4. 新的 AOF 的文件进行改名，覆盖现有的 AOF 文件

### RDB

就是把当前的内存全量复制到RDB文件里

也是用到了写时复制技术，所以写到RDB文件里的实际上是快照

### 混合持久化

由于RDB恢复速度快，但是如果发生意外丢失的数据比较多

AOF发生意外丢失的数据少，但是恢复速度慢，所以出现了混合持久化的方案

就是AOF文件重写的时候，先将内存数据以RDB的方式保存到AOF文件，然后追加命令像普通的AOF方式一样

**优点：**

1. 混合持久化结合了 RDB 和 AOF 持久化的优点，恢复速度快，如果发生意外丢失的数据少

**缺点：**

1. AOF 文件中添加了 RDB 格式的内容，使得 AOF 文件的可读性变得很差；
2. 兼容性差，如果开启混合持久化，那么此混合持久化 AOF 文件，就不能用在 Redis 4.0 之前版本了。

## 集群

集群就是多个redis节点统一提供服务，哨兵就是如果主节点挂了那就由哨兵选出来一个新的主节点，内容比较碎，直接看：

<https://www.xiaolincoding.com/redis/cluster/sentinel.html>

<https://www.xiaolincoding.com/redis/cluster/master_slave_replication.html>

### Redis 如何实现服务高可用

1. 主从复制
2. 哨兵模式

#### 主从复制

主从复制是 Redis 高可用服务的最基础的保证，实现方案就是将从前的一台 Redis 服务器，同步数据到多台从 Redis 服务器上，即一主多从的模式，且主从服务器之间采用的是「读写分离」的方式。

![img](https://cdn.xiaolincoding.com//mysql/other/2b7231b6aabb9a9a2e2390ab3a280b2d.png)

主从服务器之间的命令复制是**异步**进行的

并且主服务器不会等待从服务器执行完毕之后再返回响应给客户端，所以从服务器接收到主服务器的写命令之前，是存在数据不一致的现象的

#### 哨兵模式

在使用 Redis 主从服务的时候，会有一个问题，就是当 Redis 的主从服务器出现故障宕机时，需要手动进行恢复。

为了解决这个问题，Redis 增加了哨兵模式（**Redis Sentinel**），因为哨兵模式做到了可以监控主从服务器，并且提供**主从节点故障转移的功能。**

![img](https://cdn.xiaolincoding.com//mysql/other/26f88373d8454682b9e0c1d4fd1611b4.png)

### 集群脑裂导致数据丢失怎么办

#### 脑裂问题是什么

由于网络问题，集群节点之间失去联系。主从数据不同步；重新平衡选举，产生两个主服务。等网络恢复，旧主节点会降级为从节点，再与新主节点进行同步复制的时候，由于从节点会清空自己的缓冲区，所以导致之前客户端写入的数据丢失了。

#### 解决方案

当主节点发现从节点下线或者通信超时的总数量大于阈值时，那么禁止主节点进行写数据，直接把错误返回给客户端。

出现主节点网络不通畅的时候原主库就会被限制接收客户端写请求，客户端也就不能在原主库中写入新数据了。

等到新主库上线时，就只有新主库能接收和处理客户端请求，此时，新写的数据会被直接写到新主库中。而原主库会被哨兵降为从库，即使它的数据被清空了，也不会有新数据丢失。

## 过期删除与内存淘汰

过期删除是删除过期的键值对，内存淘汰是，内存满了，怎么把一些淘汰掉即使这些键值对没有过期

### 过期删除

有三种策略：

- 定时删除：设置key的时候就设置一个定时删除事件
- 惰性删除：不主动删除，每次访问键值对的时候，如果过期了就删除
- 定期删除：每隔一段时间随机选出来一定数量的key删除

redis使用的惰性删除+定期删除

### 内存淘汰

常用的有两种：

- lru：淘汰最久未使用的键值
- lfu：淘汰最少使用的键值

### Redis 持久化时，对过期键会如何处理

#### RDB

- **RDB 文件生成阶段**：过期的键「不会」被保存到新的 RDB 文件中
- **RDB 加载阶段**：如果是主服务器的话，过期键「不会」被载入到数据库中，如果是从服务器的话，过期键「会」被载入到数据库中，因为反正以后数据同步的时候会清空

#### AOF

- **AOF 文件写入阶段**：如果数据库某个过期键还没被删除，那么 AOF 文件会保留此过期键，当此过期键被删除后，Redis 会向 AOF 文件追加一条 DEL 命令来显式地删除该键值。
- **AOF 重写阶段**：已过期的键不会被保存到重写后的 AOF 文件中

### Redis 主从模式中，对过期键会如何处理

从库不会进行过期扫描，从库对过期的处理是被动的，主库在 key 到期时，会在 AOF 文件里增加一条 del 指令，同步到所有的从库

### LRU vs LFU

- lru：淘汰整个键值中最久未使用的键值
- lfu：淘汰整个键值中最少使用的键值

## 缓存

### 缓存雪崩、击穿、穿透

#### 雪崩

![图片](https://img-blog.csdnimg.cn/img_convert/717343a0da7a1b05edab1d1cdf8f28e5.png)

#### 击穿

![图片](https://img-blog.csdnimg.cn/img_convert/acb5f4e7ef24a524a53c39eb016f63d4.png)

#### 穿透

![图片](https://img-blog.csdnimg.cn/img_convert/b7031182f770a7a5b3c82eaf749f53b0.png)

#### 如何避免缓存雪崩

1. **将缓存失效时间随机打散**
2. **设置缓存不过期**，我们可以通过后台服务来更新缓存数据

#### 如何避免缓存击穿

1. 互斥锁方案，保证同一时间只有一个业务线程请求缓存
2. 不给热点数据设置过期时间，由后台异步更新缓存

#### 如何避免缓存穿透

1. **限制非法请求**
2. **设置空值或者默认值**：当我们线上业务发现缓存穿透的现象时，可以针对查询的数据，在缓存中设置一个空值或者默认值
3. **使用布隆过滤器快速判断数据是否存在，避免通过查询数据库来判断数据是否存在**

### 数据库和缓存如何保证一致性？

先更新数据库，再删除缓存，因为比如是先删除缓存，再更新数据库的话，可能还没更新数据库呢，缓存就被另一个线程给填上了

具体原因看：<https://www.xiaolincoding.com/redis/architecture/mysql_redis_consistency.html>

### 缓存更新策略

- Cache Aside（旁路缓存）策略：Cache Aside（旁路缓存）策略是最常用的，应用程序直接与「数据库、缓存」交互，并负责对缓存的维护，该策略又可以细分为「读策略」和「写策略」。
- Read/Write Through（读穿 / 写穿）策略：Read/Write Through（读穿 / 写穿）策略原则是应用程序只和缓存交互，不再和数据库交互，而是由缓存和数据库交互，相当于更新数据库的操作由缓存自己代理了。
- Write Back（写回）策略：Write Back（写回）策略在更新数据的时候，只更新缓存，同时将缓存数据设置为脏的，然后立马返回，并不会更新数据库。对于数据库的更新，会通过批量异步更新的方式进行。

## 实战

### 实现延迟队列

看小林coding

### 大key怎么删除

先查找大key，可以用

- ***redis-cli --bigkeys 查找大key***
- ***使用 SCAN 命令查找大 key***
- ***使用 RdbTools 工具查找大 key***

然后删除，可以用

- ***分批次删除***
- unlink异步删除

### Redis 管道有什么用？

可以一次发送多条指令

### Redis 事务支持回滚吗？

不支持

### 如何用 Redis 实现分布式锁的？

分布式锁就是分布式的应用访问同一个资源的锁，对于多个应用，加锁方式是在redis里面设置一个值，添加NX字段，这个字段说明这个值必须不存在才能添加成功，那么谁能添加值成功，谁就拿到了分布式锁

# Java

## 基础

### 未看

<https://javaguide.cn/java/basis/unsafe.html>

<https://javaguide.cn/java/basis/spi.html>

<https://javaguide.cn/java/basis/syntactic-sugar.html>

<https://javaguide.cn/java/collection/concurrent-hash-map-source-code.html>

<https://www.xiaolincoding.com/os/8_network_system/selete_poll_epoll.html>

## 并发

### 线程生命周期

![Java 线程状态变迁图](https://oss.javaguide.cn/github/javaguide/java/concurrent/640.png)

- NEW: 初始状态，线程被创建出来但没有被调用 `start()` 。

- RUNNABLE: 运行状态，线程被调用了 `start()`等待运行的状态。

- BLOCKED ：阻塞状态，需要等待锁释放。

- WAITING：等待状态，表示该线程需要等待其他线程做出一些特定动作（通知或中断）。

- TIME_WAITING：超时等待状态，可以在指定的时间后自行返回而不是像 WAITING 那样一直等待。

- TERMINATED：终止状态，表示该线程已经运行完毕。

join()和sleep()方法会进入WAITING或者TIME_WAITING状态，IO操作Java线程的状态是RUNNABLE，操作系统的状态是Sleep

### 创建线程的三种方式的对比

#### 采用实现Runnable. Callable接口的方式创建多线程

**优势是**：

线程类只是实现了Runnable接口或Callable接口，还可以继承其他类。

在这种方式下，多个线程可以共享同一个target对象，所以非常适合多个相同线程来处理同一份资源的情况，从而可以将CPU. 代码和数据分开，形成清晰的模型，较好地体现了面向对象的思想。

**劣势是：**

编程稍微复杂，如果要访问当前线程，则必须使用Thread.currentThread()方法。

#### 使用继承Thread类的方式创建多线程

**优势是：**

编写简单，如果需要访问当前线程，则无需使用Thread.currentThread()方法，直接使用this即可获得当前线程。

**劣势是：**

线程类已经继承了Thread类，所以不能再继承其他父类。

#### Runnable和Callable的区别

1. Callable规定（重写）的方法是call()，Runnable规定（重写）的方法是run()。
2. Callable的任务执行后可返回值，而Runnable的任务是不能返回值的。
3. Call方法可以抛出异常，run方法不可以。
4. 运行Callable任务可以拿到一个Future对象，表示异步计算的结果。它提供了检查计算是否完成的方法，以等待计算的完成，并检索计算的结果。通过Future对象可以了解任务执行情况，可取消任务的执行，还可获取执行结果。

### sleep() 方法和 wait() 方法对比

**共同点** ：两者都可以暂停线程的执行。

**区别** ：

- **`sleep()` 方法没有释放锁，而 `wait()` 方法释放了锁** 。
- `wait()` 通常被用于线程间交互/通信，`sleep()`通常被用于暂停执行。
- `wait()` 方法被调用后，线程不会自动苏醒，需要别的线程调用同一个对象上的 `notify()`或者 `notifyAll()` 方法。`sleep()`方法执行完成后，线程会自动苏醒，或者也可以使用 `wait(long timeout)` 超时后线程会自动苏醒。
- `sleep()` 是 `Thread` 类的静态本地方法，`wait()` 则是 `Object` 类的本地方法。为什么这样设计呢？

### wait()和notify()

- 在`synchronized`内部可以调用`wait()`使线程进入等待状态；
- 必须在已获得的锁对象上调用`wait()`方法；
- 在`synchronized`内部可以调用`notify()`或`notifyAll()`唤醒其他等待线程；
- 必须在已获得的锁对象上调用`notify()`或`notifyAll()`方法；
- 已唤醒的线程还需要重新获得锁后才能继续执行。

### volatile的作用和原理

**volatile的两层语义**：

1. volatile保证变量对所有线程的可见性：当volatile变量被修改，会立即刷新主存里的值，并且使得其他线程共享的该volatile变量无效化，所以每个线程都可以获得最新的值。
2. jdk1.5以后volatile完全避免了指令重排优化，实现了有序性。

**volatile的原理:**

volatile多加了lock addl指令，这个操作相当于一个内存屏障，使得lock指令后的指令不能重排序到内存屏障前的位置。这也是为什么JDK1.5以后可以使用双锁检测实现单例模式。

lock前缀的另一层意义是使得本线程工作内存中的volatile变量值立即写入到主内存中，并且使得其他线程共享的该volatile变量无效化，这样其他线程必须重新从主内存中读取变量值。

### CAS是什么

CAS：全称 `Compare and swap`，即**比较并交换**。当变量值等于预期值的时候才更新变量值，否则不会执行任何操作，CAS是一种原子操作，执行过程中不会被打断

#### CAS的缺陷

**1. ABA 问题**

并发环境下，假设初始条件是A，去修改数据时，发现是A就会执行修改。但是看到的虽然是A，中间可能发生了A变B，B又变回A的情况。此时A已经非彼A，数据即使成功修改，也可能有问题。

可以通过AtomicStampedReference**解决ABA问题**，它，一个带有标记的原子引用类，通过控制变量值的版本来保证CAS的正确性。

**2. 循环时间长开销**

自旋CAS，如果一直循环执行，一直不成功，会给CPU带来非常大的执行开销。

很多时候，CAS思想体现，是有个自旋次数的，就是为了避开这个耗时问题~

**3. 只能保证一个变量的原子操作。**

CAS 保证的是对一个变量执行操作的原子性，如果对多个变量操作时，CAS 目前无法直接保证操作的原子性的。

**可以通过这两个方式解决这个问题**：

- 使用互斥锁来保证原子性；
- 将多个变量封装成对象，通过AtomicReference来保证原子性。

### Synchronized的作用

1. 原子性：确保线程互斥的访问同步代码；
2. 可见性：保证共享变量的修改能够及时可见，因为在加锁和解锁的时候都会更新为最新变量的值
3. 有序性：可有效解决重排序问题

### synchronized 底层实现原理

synchronized 同步代码块的实现是通过 monitorenter 和 monitorexit 指令，其中 monitorenter 指令指向同步代码块的开始位置，monitorexit 指令则指明同步代码块的结束位置。当执行 monitorenter 指令时，线程试图获取锁也就是获取 monitor(monitor对象存在于每个Java对象的对象头中，synchronized 锁便是通过这种方式获取锁的，也是为什么Java中任意对象可以作为锁的原因) 的持有权。

其内部包含一个计数器，当计数器为0则可以成功获取，获取后将锁计数器设为1也就是加1。相应的在执行 monitorexit 指令后，将锁计数器设为0，表明锁被释放。如果获取对象锁失败，那当前线程就要阻塞等待，直到锁被另外一个线程释放为止

### synchronized 锁升级



### synchronized 和 volatile 的区别是什么

`synchronized` 关键字和 `volatile` 关键字是两个互补的存在，而不是对立的存在！

- `volatile` 关键字是线程同步的轻量级实现，所以 `volatile`性能肯定比`synchronized`关键字要好 。但是 `volatile` 关键字只能用于变量而 `synchronized` 关键字可以修饰方法以及代码块 。
- `volatile` 关键字能保证数据的可见性，但不能保证数据的原子性。`synchronized` 关键字两者都能保证。
- `volatile`关键字主要用于解决变量在多个线程之间的可见性，而 `synchronized` 关键字解决的是多个线程之间访问资源的同步性。

### ReentrantLock是什么

ReetrantLock是一个可重入的独占锁，主要有两个特性，一个是支持公平锁和非公平锁，一个是可重入。 ReetrantLock实现依赖于AQS(AbstractQueuedSynchronizer)。

ReetrantLock主要依靠AQS维护一个阻塞队列，多个线程对加锁时，失败则会进入阻塞队列。等待唤醒，重新尝试加锁。

### synchronized 和 ReentrantLock 的联系与区别

**相同点：**

1. 两者都是可重入锁

**不同点：**

1. synchronized 依赖于 JVM 而 ReentrantLock 依赖于 API
2. ReentrantLock 比 synchronized 增加了一些高级功能：
   1. 等待可中断
   2. 可实现公平锁（synchronized 是非公平锁）
   3. 可实现选择性通知（锁可以绑定多个条件）

### ReadWriteLock是什么

首先ReentrantLock某些时候有局限，如果使用ReentrantLock，可能本身是为了防止线程A在写数据、线程B在读数据造成的数据不一致，但这样，如果线程C在读数据、线程D也在读数据，读数据是不会改变数据的，没有必要加锁，但是还是加锁了，降低了程序的性能。

因为这个，才诞生了读写锁ReadWriteLock。ReadWriteLock是一个读写锁接口，ReentrantReadWriteLock是ReadWriteLock接口的一个具体实现，实现了读写的分离，读锁是共享的，写锁是独占的，读和读之间不会互斥，读和写、写和读、写和写之间才会互斥，提升了读写的性能

### ThreadLocal是什么

ThreadLocal，即线程本地变量。如果你创建了一个ThreadLocal变量，那么访问这个变量的每个线程都会有这个变量的一个本地拷贝，多个线程操作这个变量的时候，实际是操作自己本地内存里面的变量，从而起到线程隔离的作用，避免了线程安全问题。

#### 原理

ThreadLocal里面每个线程都有一个Map，Map的key就是threadLocal对象本身，value是副本对象

#### 内存泄漏问题

`ThreadLocalMap` 中使用的 key 为 `ThreadLocal` 的弱引用，而 value 是强引用。所以，如果 `ThreadLocal` 没有被外部强引用的情况下，在垃圾回收的时候，key 会被清理掉，而 value 不会被清理掉。

这样一来，`ThreadLocalMap` 中就会出现 key 为 null 的 Entry。假如我们不做任何措施的话，value 永远无法被 GC 回收，这个时候就可能会产生内存泄露。`ThreadLocalMap` 实现中已经考虑了这种情况，在调用 `set()`、`get()`、`remove()` 方法的时候，会清理掉 key 为 null 的记录。使用完 `ThreadLocal`方法后 最好手动调用`remove()`方法

### execute()和submit()的区别

- `execute()` 方法用于提交不需要返回值的任务，所以无法判断任务是否被线程池执行成功与否
- submit()方法用于提交需要返回值的任务。线程池会返回一个future类型的对象，通过这个future对象可以判断任务是否执行成功

### 线程池核心参数

- corePoolSize ： 核心线程大小。线程池一直运行，核心线程就不会停止。

- maximumPoolSize ：线程池最大线程数量。非核心线程数量=maximumPoolSize-corePoolSize

- keepAliveTime ：非核心线程的心跳时间。如果非核心线程在keepAliveTime内没有运行任务，非核心线程会消亡。

- workQueue ：阻塞队列。ArrayBlockingQueue，LinkedBlockingQueue等，用来存放线程任务。

- defaultHandler ：饱和策略。ThreadPoolExecutor类中一共有4种饱和策略。通过实现

  RejectedExecutionHandler

  接口。

  - AbortPolicy ： 线程任务丢弃报错。默认饱和策略。
  - DiscardPolicy ： 线程任务直接丢弃不报错。
  - DiscardOldestPolicy ： 将workQueue**队首任务丢弃**，将最新线程任务重新加入队列执行。
  - CallerRunsPolicy ：线程池之外的线程直接调用run方法执行。

- ThreadFactory ：线程工厂。新建线程工厂。

### 线程池执行任务的流程

![图解线程池实现原理](https://oss.javaguide.cn/javaguide/%E5%9B%BE%E8%A7%A3%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86.png)

### 常用的JAVA线程池有哪几种

- newCachedThreadPool
- newFixedThreadPool
- newSingleThreadExecutor
- newScheduleThreadPool

### 线程池常用的阻塞队列有哪些

![阻塞队列](http://blog-img.coolsen.cn/img/20200722164307306.png)

### 如何合理配置线程池线程数

CPU密集型：corePoolSize = CPU核数 + 1

IO密集型：corePoolSize = CPU核数 * 2

### Atomic 原子类是什么

就是操作都是原子操作的类

#### 原理

AtomicInteger 类主要利用 CAS和 volatile 和 native 方法来保证原子操作，从而避免 synchronized 的高开销，执行效率大为提升。

### AQS



# 零碎

- 匿名内部类也会生成class文件
- transferTo方法是什么？

是Java提供的零拷贝文件传输函数，需要操作系统的支持，Netty的文件传输就采用了Java的transferTo方法，详见上面`Netty 的零拷贝`的解释

# 待做

- jdk动态代理的反射体现在什么地方？
- 主从多线程模型到底是什么
- Netty的内存池是怎么实现的
- 五种IO模型
- 各种序列化方式的原理
- CAP为什么不能保证三个
- 布隆过滤器是什么
- synchronized 锁升级
- 看一下常用的线程池和阻塞队列
- AQS
